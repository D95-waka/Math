\input{../article_base.tex}
\title{תורת ההסתברות 1 --- סיכום}
\setcounter{secnumdepth}{2}
% chktex-file 9
% chktex-file 17

\hypersetup{}
\begin{document}
\maketitle
\maketitleprint{}

\tableofcontents

\section{שיעור 1 --- 29.10.2024}

\subsection{מבוא הקורס}
% אורי גורביץ' הוא המרצה, הקורס הוא מבוא להסתברות. הוא חצי חירש תתמודד עם זה במקרה הצורך.
נלמד לפי ספר שעוד לא יצא לאור שנכתב על־ידי אורי עצמו, הוא עוד לא סופי ויש בו בעיות ואי־דיוקים, תשיג את הספר הזה.
כן יש הבדל בין הקורס והספר אז לא לסמוך על הסדר שלו גם כשאתה משיג אותו, אבל זו תוספת מאוד נוחה.
יש סימון של כוכביות לחומר מוסף, כדאי לעבור עליו לקראת המבחן כי זה יתן לנו עוד אינטואיציה והעמקה של ההבנה.

נשים לב כי ענף ההסתברות הוא ענף חדש יחסית, שהתפתח הרבה אחרי שאר הענפים הקלאסיים של המתמטיקה, למעשה רק לפני 400 שנה נשאלה על־ידי נזיר במהלך חקר של משחק אקראי השאלה הראשית של העולם הזה, מה ההסתברות של הצלחה במשחק.

נעבור לדבר על פילוסופיה של ההסתברות.
מה המשמעות של הטלת מטבע מבחינת הסתברות?
ישנה הגישה של השכיחות, שמציגה הסתברות כתוצאה במקרה של חזרה על ניסוי כמות גדולה מאוד של פעמים.
יש כמה בעיות בזה, לרבות חוסר היכולת להגדיר במדויק אמירה כזו, הטיות שנובעות מפיזיקה, מטבעות הם לא מאוזנים לדוגמה.
הבעיה הראשית היא שלא לכל בעיה אפשר לפנות בצורה כזאת.
ישנה גישה נוספת, היא הגישה האוביקטיבית או המתמטית, הגישה הזו בעצם היא תרגום בעיה מהמציאות לבעיה מתמטית פורמלית.
לדוגמה נשאל את השאלה מה ההסתברות לקבל 6 בהגרלה של כל המספרים מ־1 עד מיליון.
השיטה ההסתברותית קובעת שאם אני רוצה להוכיח קיום של איזשהו אוביקט, לפעמים אפשר לעשות את זה על־ידי הגרלה של אוביקט כזה והוכחה שיש הסתברות חיובית שהוא יוגרל, וזו הוכחה שהוא קיים.
מה התחזיות שינבעו מתורת ההסתברות? לדוגמה אי־אפשר לחזות הטלת מטבע בודדת, אבל היא כן נותנת הבנה כללית של הטלת 1000 מטבעות, הסתברויות קטנות מספיק יכולות להיות זניחות ובמקרה זה נוכל להתעלם מהן.
לפחות בתחילת הקורס נדבר על תרגום של בעיות מהמציאות לבעיות מתמטיות, זה אומנם חלק פחות ריגורזי, אבל הוא כן חשוב ליצירת קישור בין המציאות לבין החומר הנלמד.

דבר אחרון, ישנה השאלה הפילוסופית של האם באמת יש הסתברות שכן לא בטוח שיש אקראיות בטבע, הגישה לנושא מבחינה פיזיקלית קצת השתנתה בעת האחרונה וקשה לענות על השאלה הזאת.
יש לנו תורות פיזיקליות שהן הסתברותיות בעיקרן, כמו תורת הקוונטים, תורה זו לא סתם הסתברותית, אנחנו לא מנסים לפתור בעיות הסתברותיות אלא ממש משתמשים במודלים סטטיסטיים כדי לתאר מצב בעולם.
לדוגמה נוכל להסיק ככה מסקנה פשוטה שאם מיכל גז נפתח בחדר, יהיה ערבוב של הגז הפנימי ושל אוויר החדר, זוהי מסקנה הסתברותית.
החלק המדהים הוא שתורת הקוונטים מניחה חוסר דטרמניזם כתכונה יסודית ועד כמה שאפשר לראות יש ניסויים שמוכיחים שבאמת יש חוסר ודאות בטבע.
דהינו שברמה העקרונית הפשוטה באמת אין תוצאה ודאית בכלל למצבים כאלה במציאות.

\subsection{מרחבי מדגם ופונקציית הסתברות}
\begin{definition}[מרחב מדגם]
	מרחב מדגם הוא קבוצה לא ריקה שמהווה העולם להסתברות. \\*
	נסמנה $\Omega$.
	איבר במרחב המדגם נסמן ב־$\omega \in \Omega$ על־פי רוב.
\end{definition}
נוכל להגיד שמרחב במדגם הוא הקבוצה של האיברים שעליה אנחנו שואלים בכלל שאלות, זהו הייצוג של האיברים או המצבים שמעניינים אותנו.
בהתאם נראה עכשיו מספר דוגמות שמקשרות בין אובייקטים שאנו דנים בהם בהסתברות ובהגדרה פורמלית של מרחבי מדגם עבורם.
\begin{example}[מרחבי הסתברות שונים]
	נראה מספר דוגמות למצבים כאלה:
	\begin{itemize}
		\item הטלת מטבע תוגדר על־ידי $\Omega = \{ H, T \}$.
		\item הטלת שלושה מטבעות תהיה באופן דומה $\Omega = {\{H, T\}}^3$.
		\item הטלת קוביה היא $\Omega = [6] = \{ 1, \dots, 6 \}$.
		\item הטלת מטבע ואז אם יוצא עץ (H) אז מטילים קוביה ואם יוצא פלי (T) אז מטילים קוביה עם 8 פאות. \\*
			במקרה זה נסמן $\Omega = \{ H1, H2, H3, \dots, H6, T1, \dots, T8 \} = \{H, T \} \times \{1, \dots, 8 \}$ כאשר הכוונה פה היא לזוג סדור $\langle H, 1 \rangle$.
		\item ערבוב חפיסת קלפים, במקרה זה מרחב המדגם שלנו יהיה סימון של הקלפים כרשימה מספרית בלבד, דהינו $\Omega = S_{52}$. \\*
			נוכל גם לסמן במקום את $\Omega = {\{1, \dots, 52 \}}^{52}$, זהו סימון זהה.
	\end{itemize}
\end{example}
בדוגמה זו קל במיוחד לראות שכל איבר בקבוצה מתאר מצב סופי כלשהו, ואנו יכולים לשאול שאלות הסתברותיות מהצורה מה הסיכוי שנקבל $\omega$ מסוים מתוך $\Omega$, זאת ללא התחשבות בבעיה שממנה אנו מגיעים.
נבחן עתה גם דוגמות למקרים שבהם אין לנו מספר סופי של אפשרויות, למעשה מקרים אלה דומים מאוד למקרים שראינו עד כה.
\begin{example}[מרחבי מדגם לא סופיים]
	מטילים מטבע עד שיוצא $H$, אז מרחב המדגם הוא $\Omega = \NN \cup \{ \infty \}$. \\*
	באופן דומה נוכל לבחון מדידת זמן התפרקות חלקיק, היא $\Omega = \RR_+ \cup \{ \infty \}$.
\end{example}
\begin{definition}[פונקציית הסתברות נקודתית]
	יהי מרחב מדגם $\Omega$ ותהי $p : \Omega \to [0, \infty)$ פונקציה כך שמתקיים
	\[
		\sum_{\omega \in \Omega} p(\omega) = 1
	\]
	אז פונקציה זו נקראת \textbf{פונקציית הסתברות}.
\end{definition}
למעשה פונקציית הסתברות היא מה שאנחנו נזהה עם הסתברות במובן הפשוט, פונקציה זו מגדירה לנו לכל סיטואציה ממרחב המדגם מה הסיכוי שנגיע אליה, כך לדוגמה אם נאמר שהטלת מטבע תגיע בחצי מהמקרים לעץ ובחצי השני לפלי,
אז זו היא פונקציית ההסתברות עצמה, פונקציה שמחזירה חצי עבור עץ וחצי עבור פלי, נראה מספר דוגמות.
\begin{example}[פונקציית הסתברות להטלת מטבע]
	נגדיר $\Omega = \{ H, T \}$ ויהי $0 \le \alpha \le 1$, נגדיר $p(H) = \alpha, p(T) = 1 - \alpha$.
\end{example}
\begin{example}[פונקציית הסתברות אינסופית]
	נגדיר $\Omega = \NN \cup \{ \infty \}$ ו־$p(\omega) = \begin{cases}
		2^{-\omega} & \omega \in \NN \\
		0 & \omega = \infty
	\end{cases}$.
	בדוגמה זו נקבל $\sum_{n = 1}^{\infty} 2^{-n} = 1$ ולכן זו אכן פונקציית הסתברות.
\end{example}
נבחין כי הדוגמה האחרונה מתארת לנו התפלגות של דעיכה, זאת אומרת שלדוגמה אם קיים חלקיק עם זמן מחצית חיים של יחידה אחת, פונקציית הסתברות זו תניב לנו את הסיכוי שהוא התפרק לאחר כמות יחידות זמן כלשהי.
\begin{example}
	נגדיר $\Omega = \NN$ ו־$p(\omega) = \frac{1}{\omega(\omega + 1)}$, נבחין כי אכן $\sum_{n = 1}^{\infty} \frac{1}{n(n + 1)} = 1$.
\end{example}
\begin{definition}[תומך]
	התומך של $p$ הוא $\text{Supp}(p) = \{ \omega \in \Omega \mid p(\omega) > 0 \}$. \\*
	נבחין כי התומך הוא למעשה קבוצת האיברים שאפשרי לקבל לפי פונקציית ההסתברות, כל שאר המצבים מקבלים 0, משמעו הוא שאין אפשרות להגיע אליו.
\end{definition}
\begin{remark}
	נבחין כי תמיד $\mathcal{F} \subseteq \mathcal{P}(\Omega)$.
\end{remark}
\begin{definition}[מאורע]
	מאורע הוא תת־קבוצה של מרחב המדגם, קבוצת כל המאורעות תסומן $\mathcal{F}$.
	עבור מאורע $A$ המאורע המשלים מסומן ב־$A^C = \Omega \setminus A$.
\end{definition}
\begin{definition}[פונקציית הסתברות]
	נגדיר עתה פונקציית הסתברות שאיננה נקודתית.
	יהי מרחב מדגם $\Omega$ וקבוצת מאורעות $\mathcal{F}$. \\*
	תהי $\PP : \mathcal{F} \to [0, \infty)$ המקיימת את התכונות הבאות:
	\begin{enumerate}
		\item $\PP(\Omega) = 1$
		\item לכל ${\{A_i\}}_{i = 1}^\infty \subseteq \mathcal{F}$ סדרת מאורעות שונים מתקיים
			\[
				\sum_{i \in \NN} \PP(A_i) = \PP(\bigcup_{i \in \NN} A_i)
			\]
			דהינו, הפונקציה סכימה בתת־קבוצות בנות מניה.
	\end{enumerate}
	לפונקציה כזו נקרא \textbf{פונקציית ההסתברות} על $(\Omega, \mathcal{F})$.
\end{definition}
\begin{proposition}
	תהי $p$ פונקציית הסתברות נקודתית על $\Omega$ אז נגדיר פונקציית הסתברות $\PP_p$ על־ידי
	\[
		\PP_p(A) = \sum_{\omega \in A} p(\omega)
	\]
	אז $\PP_p$ היא פונקציית הסתברות.
\end{proposition}
\begin{proof}
	נוכיח ששתי התכונות של פונקציית הסתברות מתקיימות.
	\[
		\PP_p(A) = \sum_{\omega \in A} p(\omega) \ge 0
	\]
	שכן זהו סכום אי־שלילי מהגדרת $p$,
	בנוסף נקבל מההגדרה של $p$ כי
	\[
		\PP_p(\Omega) = \sum_{\omega \in \Omega} p(\omega) = 1
	\]
	וקיבלנו כי התכונה הראשונה מתקיימת. \\*
	תהי ${\{A\}}_{i = 1}^\infty \in \mathcal{F}$, אז נקבל
	\[
		\sum_{i \in \NN} \PP_p(A_i) = \sum_{i \in \NN} \left( \sum_{\omega \in A_i} p(\omega) \right) = \sum_{\omega \in \bigcup_{i \in \NN} A_i} p(\omega) = \PP_p(\bigcup_{i \in \NN} A_i)
	\]
	ולכן גם התכונה השנייה מתקיימת וקיבלנו כי $\PP_p$ היא אכן פונקציית הסתברות.
\end{proof}
נשים לב כי בעוד פונקציית הסתברות נקודתית מאפשרת לנו לדון בהסתברות של איבר בודד בקבוצות בנות מניה, פונקציית הסתברות למעשה מאפשרת לנו לדון בהסתברות של מאורעות, הם קבוצות של כמה מצבים אפשריים, ובכך להגדיל את מושא הדיון שלנו.
מהטענה האחרונה גם נוכל להסיק שבין שתי ההגדרות קיים קשר הדוק, שכן פונקציית הסתברות נקודתית גוררת את קיומה של פונקציית הסתברות כללית.

\section{תרגול 1 --- 31.10.2024}
המתרגל הוא אמיר, amir.behar@mail.huji.ac.il

\subsection{מרחבי הסתברות סופיים ובני־מניה}
ניזכר בהגדרה למרחב הסתברות, המטרה של הגדרה זו היא לתאר תוצאות אפשריות של מצב נתון.
\begin{definition}[מרחב הסתברות]
	מרחב הסתברות הוא קבוצה $(\Omega, \mathcal{F}, \PP)$ כאשר $\PP : \mathcal{F} \to [0, 1]$, כך שמתקיים
	\begin{enumerate}
		\item חיוביות: $\forall A \in \mathcal{F}, \PP(A) \ge 0$
		\item נרמול: $\PP(\Omega) = 1$
		\item סיגמא־אדיטיביות: $\forall {\{ A_i \}}_{i = 1}^\infty \in \mathcal{F}, (\forall i, j \in \NN, i \ne j \implies A_i \cap A_j = \emptyset) \implies \sum_{i \in I} \PP(A_i) = \PP(\bigcup_{i \in I} A_i )$
	\end{enumerate}
\end{definition}
\begin{exercise}
	יהי $(\Omega, \mathcal{F}, \PP)$ מרחב הסתברות, $A, B \in \mathcal{F}$, הוכיחו
	\[
		\PP(A \cup B) = \PP(A) + \PP(B) - \PP(A \cap B)
	\]
\end{exercise}
\begin{proof}
	נבחין כי $\PP(A) = \PP(A - (A \cap B)) + \PP(A \cap B)$ וגם $\PP(B) = \PP(B - (A \cap B)) + \PP(A \cap B)$. נוכל אם כן לסכום ולקבל
	\[
		\PP(A) + \PP(B) = \PP(A - (A \cap B)) + \PP(A \cap B) + \PP(B - (A \cap B)) + \PP(A \cap B)
		= \PP(A \cup B) + \PP(A \cap B)
	\]
	נבחין כי השוויון האחרון נובע מהזרות של קבוצות אלה.
\end{proof}
לאורך פרק זה נגדיר מעתה שמתקיים $\Omega$ סופית, $\mathcal{F} = 2^\Omega$ ואף נגדיר כי ההסתברות אחידה, דהינו $\forall A \enspace \PP(A) = \frac{|A|}{|\Omega|}$, זה כמובן שקול לטענה
\[
	\forall \omega, \omega' \in \Omega, \PP(\{\omega\}) = \PP(\{\omega'\})
\]
\begin{exercise}
	מטילים קוביה הוגנת, מה ההסתברות שיצא מספר זוגי?
\end{exercise}
\begin{solution}
	נגדיר $\Omega = [6] = \{1, \dots, 6\}$, עם $\PP$ אחידה. \\*
	נרצה לחשב את $A = \{2, 4, 6\}$ ולכן נקבל $\PP(A) = \frac{|A|}{|\Omega|} = \frac{3}{6} = \frac{1}{2}$.
\end{solution}
\begin{exercise}
	מטילים מטבע הוגן שלוש פעמים, מה ההסתברות שיצא עץ בדיוק פעמיים, ומה ההסתברות שיצא עץ לפחות פעמיים?
\end{exercise}
\begin{solution}
	נגדיר $\Omega = \{ TTT, TTP, TPT, PTT, \dots \}$. \\*
	עבור המקרה הראשון נגדיר $A = \{ TTP, TPT, PTT \}$, ולכן נקבל שההסתברות היא $\PP(A) = \frac{3}{8}$. \\*
	במקרה השני נקבל $B = A \cup \{ TTT \}$ ולכן $P(B) = \frac{1}{2}$.
\end{solution}
\begin{exercise}
	מטילים קוביה הוגנת $n$ פעמים.
	\begin{enumerate}
		\item מה ההסתברות שתוצאת ההטלה הראשונה קטנה מ־4?
		\item מה ההסתברות שתוצאת ההטלה הראשונה קטנה שווה מתוצאת ההטלה השנייה?
		\item מה ההסתברות שיצא 1 לפחות פעם אחת?
	\end{enumerate}
\end{exercise}
\begin{solution}
	נגדיר $\Omega = {[6]}^n = \{ (x_1, \dots, x_n) \mid x_i \in [6] \}$.
	\begin{enumerate}
		\item נגדיר $A = \{ (x_1, \dots, x_n) \in \Omega \mid x_1 < 4 \}$ ולכן $\PP(A) = \frac{3 \cdot 6^{n - 1}}{6^n} = \frac{1}{2}$.
		\item נגדיר $B = \{ (x_1, \dots, x_n) \in \Omega \mid x_1 \le x_2 \} = \bigcup_{i = 1}^6 \{ (x_1, i, x_3, \dots, x_n) \in \Omega \mid x_i \le i \}$, ולכן נקבל
			\[
				\PP(B) = \sum \PP(B_i) = \sum \frac{i \cdot 6^{n - 2}}{6^n} = \frac{\sum_{i = 1}^{6} i}{6^2} = \frac{6 \cdot 7}{6^2 \cdot 2} = \frac{7}{12}
			\]
		\item הפעם $C = \{ (x_1, \dots, x_n) \in \Omega \mid \exists i, x_i = 1 \}$, בהתאם $C^C = \{ (x_1, \dots, x_n) \in \Omega \mid \forall i, x_1 \ne 1 \}$. \\*
			לכן נקבל $\PP(C^C) = \frac{5^n}{6^n} \implies \PP(C) = 1 - \frac{5^n}{6^n}$.
	\end{enumerate}
\end{solution}
\begin{exercise}
	חמישה אנשים בריאים וחמישה אנשים חולי שפעת עומדים בשורה. מה ההסתברות שחולי השפעת נמצאים משמאל לאנשים הבריאים?
\end{exercise}
\begin{solution}
	נגדיר $\Omega$ ככל הסידורים של $0, 1$ כשיש חמישה מכל סוג.
	לכן נקבל $|\Omega| = \binom{10}{5}$, שכן $\Omega = \{ X \subset [10] \mid |X| = 5 \}$. \\*
	המאורע הפעם הוא $A = \{ \{ 1, 2, 3, 4, 5 \} \}$ ובהתאם $\PP(A) = \frac{5! 5!}{10!}$.

	נוכל גם להגדיר $\Omega = S_{10}$ כאשר חמשת המספרים הראשונים מייצגים בריאים וחמשת האחרונים מייצגים חולים. \\*
	במקרה זה נקבל $A = \{ \pi \in \Omega \mid \pi(\{1, 2, 3, 4, 5\}) \subseteq \{1, 2, 3, 4, 5\} \}$ ולכן $|A| = 5! 5! $ וכך נקבל $\PP(A) = \frac{5! 5!}{10!}$.
\end{solution}

\section{שיעור 2 --- 31.10.2024}
\subsection{השלמה לטורים דו־מימדיים}
נגדיר הגדרה שדרושה לצורך ההרצאה הקודמת כדי להיות מסוגלים לדון בסכומים אינסופיים בני־מניה.
\begin{definition}[סכום קבוצת בת־מניה]
	אם ${\{a_i\}}_{i \in I}$ ו־$a_i \ge 0$ לכל $i \in I$ אז נגדיר
	\[
		\sum_{i \in I} a_i = \sup \left\{ \sum_{i \in J} \mid J \subseteq I, J \text{ is finite} \right\}
	\]
\end{definition}

\subsection{תכונות של פונקציות הסתברות}
נעבור עתה לבחון פונקציות הסתברות ואת תכונותיהן, נתחיל מתרגיל שיוצק תוכן לתומך של פונקציית הסתברות:
\begin{exercise}
	הוכיחו כי אם $\sum_{i \in I} a_i < \infty$ ו־$a_i \ge 0$ לכל $i \in I$ אז $|\{ i \in I \mid a_i < 0 \}| \le \aleph_0$.
	במילים אחרות הוכיחו כי התומך של $a$ הוא בן־מניה.
\end{exercise}
בשיעור הקודם ראינו את ההגדרה והטענה הבאות:
\begin{definition}[פונקציית הסתברות מתאימה לנקודתית]
	בהינתן פונקציית הסתברות נקודתית $p$ נגדיר
	\[
		\PP_p(A) = \sum_{\omega \in A} p(\omega)
	\]
\end{definition}
\begin{proposition}
	$\PP_p$ היא פונקציית הסתברות.
\end{proposition}
טענה זו בעצם יוצרת קשר בין פונקציות הסתברות לפונקציות הסתברות נקודתיות, ומאפשרת לנו לחקור את פונקציות ההסתברות לעומק באופן פשוט הרבה יותר. נשתמש עתה בכלי זה.
\begin{definition}[מרחב הסתברות בדיד]
	אם $\PP$ פונקציית הסתברות כך שקיימת פונקציית הסתברות נקודתית $p$ כך ש$\PP = \PP_p$, אז נאמר ש־$\PP$ היא בדידה ו־$(\Omega, \mathcal{F}, \PP)$ \textbf{מרחב הסתברות בדיד}.
\end{definition}
\begin{proposition}
	יש פונקציות הסתברות שאינן בדידות.
	בפרט, עבור מדגם ההסתברות $\Omega = [0, 1]$ קיימת פונקציית הסתברות $\PP$ המקיימת
	\[
		\forall a, b \in \RR, 0 \le a \le b \le 1 \implies \PP([a, b]) = b - a
	\]
\end{proposition}
\begin{example}
	ידוע כי $\sum_{n \in \NN} \frac{1}{n^2} = \frac{\pi^2}{6} < \infty$ ולכן נוכל להגדיר $\Omega = \NN$ ו־$p(n) = \frac{1}{\frac{\pi^2}{6} n^2}$, הגדרה זו תניב ש־$\sum_{n \in \NN} p(n) = 1$ ולכן זו פונקציית הסתברות.
	נחשב את $\PP_p(A)$ עבור $A = 2\NN$:
	\[
		\PP_p(A) = \sum_{n \in A} p(n) = \sum_{k \in \NN} p(2k) = \frac{1}{\frac{\pi^2}{6} {(2k)}^2} = \frac{6}{\pi^2} \frac{1}{4} \sum_{k \in \NN} \frac{1}{k^2} = \frac{1}{4}
	\]
	נסביר, הגדרנו פונקציית הסתברות של דעיכה, דהינו שככל שהמספר שאנו מבקשים גדול יותר כך הוא פחות סביר באופן מעריכי (לדוגמה זמן מחצית חיים), ואז שאלנו כמה סביר המאורע שבו נקבל מספר זוגי.
\end{example}
\begin{theorem}[תכונות פונקציית הסתברות]
	$\PP$ פונקציית הסתברות על $(\Omega, \mathcal{F})$, אז
	\begin{enumerate}
		\item $\PP(\emptyset) = 0$
		\item אם $I$ קבוצה סופית ו־${\{A_i\}}_{i \in I}$ מאורעות זרים בזוגות, אז $\PP(\bigcup_{i \in I} A_i) = \sum_{i \in I} \PP(A_i)$
		\item אם $A \subseteq B$ מאורעות אז $\PP(A) \le \PP(B)$
		\item $\PP(A) \le 1$ לכל מאורע $A$
		\item לכל מאורע $A$ מתקיים $\PP(A^C) = 1 - \PP(A)$
	\end{enumerate}
\end{theorem}
\begin{proof}
	נוכיח את התכונות
	\begin{enumerate}
		\item נראה כי $\PP(\emptyset) = \sum_{i = 1}^\infty \PP(\emptyset)$ שכן כל איחוד של קבוצות ריקות הוא זר, לכן אילו $\PP(\emptyset) \ne 0$ נקבל ישר סתירה, נסיק כי $\PP(\emptyset) = 0$ בלבד.
		\item נגדיר $A_i = \emptyset$ לכל $i > n$ ונשתמש בסיגמא־אדיטיביות ונקבל
			\[
				\PP(\bigcup_{i \in I} A_i)
				= \PP(\bigcup_{i \in \NN} A_i)
				= \sum_{i \in \NN} \PP(A_i)
				= \sum_{i \in I} \PP(A_i)
			\]
		\item נשתמש בתכונה 2 על $B, B \setminus A$, אלו הן קבוצות זרות כמובן, אם נגדיר $D = A \cup (B \setminus A)$ נקבל $\PP(D) = \PP(A) + \PP(B \setminus A) \ge \PP(A)$.
		\item נובע ישירות מתכונה 3 ומ־$A \subseteq \Omega$.
		\item ניזכר כי $A^C = \Omega \setminus A$ ולכן $\Omega = A \cup A^C$ ונקבל $1 = \PP(\Omega) = \PP(A) + \PP(A^C)$.
	\end{enumerate}
\end{proof}
נעבור עתה לאפיון של פונקציות הסתברות בדידות, נבין מתי הן כאלה ומתי לא.
\begin{theorem}[תנאים שקולים לפונקציית הסתברות בדידה]
	אם $(\Omega, \mathcal{F}, \PP)$ מרחב הסתברות, התנאים הבאים שקולים:
	\begin{enumerate}
		\item $\PP$ היא פונקציית הסתברות בדידה
		\item $\PP$ נתמכת על קבוצות בנות־מניה, כלומר קיימת קבוצה $A \in \mathcal{F}$ בת־מניה כך ש־$\PP(A) = 1$
		\item $\sum_{\omega \in \Omega} \PP(\{\omega\}) = 1$
		\item לכל מאורע $A \in \mathcal{F}$ מתקיים $\PP(A) = \sum_{\omega \in A} \PP(\{\omega\})$
	\end{enumerate}
\end{theorem}
\begin{proof}
	$1 \implies 2$:
	נניח ש־$\PP = \PP_p$ עבור $p : \Omega \to [0, \infty)$ פונקציית הסתברות נקודתית.
	נסתכל על $\text{Supp}(p) = \{ \omega \in \Omega \mid p(\omega) > 0 \}$, לפי הגדרת הסכום והתרגיל נובע ש־$A = \text{Supp}(p)$ בת־מניה.
	נקבל
	\[
		\PP(A) = \sum_{\omega \in A} p(\omega) = \sum_{\omega \in \Omega} p(\omega) = \PP(\Omega) = 1
	\]

	$2 \implies 4$:
	נניח ש־$\PP(S) = 1$ עבור $S$ בת־מניה. לכן $\PP(S^C) = 0$.
	נראה כי $A$ הוא איחוד זר $A = (A \cap S) \cup (A \cap S^C)$ ולכן נקבל
	\[
		\PP(A) = \PP(A \cap S) + \PP(A \cap S^C) = \PP(A \cap S) + 0 = \sum_{\omega \in A \cap S} \PP(\{\omega\}) = \sum_{\omega \in A} \PP(\{\omega\})
	\]

	$4 \implies 3$:
	אם נבחר $A = \Omega$ נקבל את טענה 3.

	$3 \implies 1$:
	נגדיר $p : \Omega \to [0, \infty)$ על־ידי $p(\omega) = \PP(\{ \omega \})$, נקבל $\sum_{\omega \in \Omega} p(\omega) = 1$ ולכן $p$ היא פונקציית הסתברות נקודתית.
	מהתרגיל והגדרת הסכום נובע ש־$S = \text{Supp}(p)$ היא בת־מניה ומתקיים $\PP(S^C) = 0$, אז לכל $A \in \mathcal{F}$ מתקיים
	\[
		\PP(A) = \PP(A \cap S) + \PP(A \cap S^C) = \PP(A \cap S) = \sum_{\omega \in A \cap S} \PP(\{ \omega \}) = \sum_{\omega \in A} \PP(\{\omega\}) = \sum_{\omega \in A} p(\omega) = \PP_p(A)
	\]
\end{proof}

\subsection{פרדוקס יום ההולדת}
פרדוקס יום ההולדת הוא פרדוקס מוכר הגורס כי גם בקבוצות קטנות יחסית של אנשים, הסיכוי שלשני אנשים שונים יהיה תאריך יום הולדת זהה הוא גבוה במידה משונה.
הפרדוקס נקרא כך שכן לכאורה אין קשר בין מספר הימים בשנה לבין הסיכוי הכל־כך גבוה שמצב זה יקרה, נבחן עתה את הפרדוקס בהיבט הסתברותי.

נניח שכל תאריכי יום ההולדת הם סבירים באותה מידה ונבחן את הפרדוקס.
נגדיר $\Omega = {[365]}^k$ עבור $k$ מספר האנשים בקבוצה נתונה כלשהי.
$p(\omega) = \frac{1}{{365}^k}$ לכל $\omega \in \Omega$.
נקבל $\PP(A) = \PP_p(A) = \frac{|A|}{365^k}$.
נרצה לחשב את $A$ כמאורע שיש לפחות שני אנשים שיש להם יום הולדת באותו יום, דהינו שיש שני ערכים זהים ברשימת המספרים, נגדיר $A = \{ \omega \in \Omega \mid \exists 1 \le i \ne j \le k, \omega_i = \omega_j \}$.
בשל המורכבות נבחן את המשלים $A^C$, נקבל $|A^C| = 365 \cdot 364 \cdots (365 - (k - 1)) = \frac{365!}{(365 - (i - 1))!}$.
נציב ונחשב:
\[
	\PP(A^C) = \frac{|A^C|}{365^k} = \prod_{i = 1}^k \frac{365 - (i - 1)}{365} = \prod_{i = 1}^k (1 - \frac{i - 1}{365})
\]
מהנוסחה שקיבלנו נראה שמההצבה $k = 23$ נקבל שההסתברות היא בערך $\frac{1}{2}$, דהינו בקבוצה של 23 אנשים יש סבירות של חצי שלפחות שניים יחגגו יום הולדת באתו יום.

\section{שיעור 3 --- 5.11.2024}

\subsection{מכפלת מרחבי הסתברות בדידים}
ניזכר תחילה במרחבי הסתברות אחידים
\begin{definition}[מרחב הסתברות אחיד]
	מרחב הסתברות אחיד הוא $(\Omega, \mathcal{F}, \PP_p)$ המקיים $p(\omega_1) = p(\omega_2)$ לכל $\omega_1, \omega_2 \in \Omega$.
\end{definition}
\begin{conclusion}
	$\PP_p(A) = \frac{|A|}{|\Omega|}$
\end{conclusion}
נבחין כי במקרים מסוימים ההסתברות שלנו מורכבת משני מאורעות בלתי תלויים, במקרים אלה נרצה להגדיר מכפלה של מרחבי ההסתברות.
\begin{definition}[מרחב מכפלת הסתברויות]
	אם $(\Omega_1, \mathcal{F}_1, \PP_{p_1})$ ו־$(\Omega_2, \mathcal{F}_2, \PP_{p_2})$ מרחבי הסתברות בדידים
	נגדיר $q : \Omega_1 \times \Omega_2 \to [0, \infty)$ על־ידי $q(\omega_1, \omega_2) = p(\omega_1) \cdot p(\omega_2)$.
\end{definition}
\begin{proposition}
	$q$ פונקציית הסתברות נקודתית.
\end{proposition}
\begin{proof}
	נשתמש ישירות בהגדרה ונחשב
	\[
		\sum_{(\omega_1, \omega_2) \in \Omega_1 \times \Omega_2} q(\omega_1, \omega_2)
		= \sum_{\omega_1 \in \Omega_1, \omega_2 \in \Omega_2} q(\omega_1, \omega_2)
		= \sum_{\omega_1 \in \Omega_1} \left( \sum_{\omega_2 \in \Omega_2} p_1(\omega_1) p_2(\omega_2) \right)
		= \sum_{\omega_1 \in \Omega_1} p_1(\omega_1)
		= 1
	\]
\end{proof}
עתה כשהוכחנו טענה זו, יש לנו הצדקה אמיתית להגדיר את $(\Omega_1 \times \Omega_2, \mathcal{F}_{1,2}, \PP_q)$ כמרחב הסתברות, ונקרא לו מרחב מכפלה.
\begin{proposition}
	אם $(\Omega_1, \mathcal{F}_1, \PP_{p_1})$ ו־$(\Omega_2, \mathcal{F}_2, \PP_{p_2})$ מרחבי הסתברות אחידים,
	אז מרחב המכפלה $(\Omega_1 \times \Omega_2, \mathcal{F}_{1,2}, \PP_q)$ אחיד אף הוא.
\end{proposition}
\begin{proof}
	\[
		q(\omega_1, \omega_2) = p_1(\omega_1) p_2(\omega_2)
		= \frac{1}{|\Omega_1|} \cdot \frac{1}{|\Omega_2|}
		= \frac{1}{|\Omega_1 \times \Omega_2|}
	\]
\end{proof}
\begin{definition}[מאורע שוליים ומאורע מכפלה]
	במרחב מכפלה המאורעות מהצורה $A \times \Omega_2$ או $\Omega_1 \times A$ נקראים שוליים. \\*
	מאורע מהצורה $A \times B$ נקרא מאורע מכפלה.
\end{definition}
\begin{proposition}
	במרחב מכפלה $\PP_q(A \times B) = \PP_{p_1}(A) \cdot \PP_{p_2}(B)$.
	בפרט $\PP_q(A \times \Omega_2) = \PP_{p_1}(A)$.
\end{proposition}
\begin{proof}
	\[
		\sum_{(\omega_1, \omega_2) \in A \times B} q(\omega_1, \omega_2)
		= \sum_{\omega_1 \in A, \omega_2 \in B} q(\omega_1, \omega_2)
		= \sum_{\omega_1 \in A} \left( \sum_{\omega_2 \in B} p_1(\omega_1) p_2(\omega_2) \right)
		= \sum_{\omega_1 \in A} p_1(\omega_1) \PP_{p_2}(B)
		= \PP_{p_1}(A) \PP_{p_2}(B)
	\]
\end{proof}
\begin{example}
	בהינתן $n$ הטלות מטבע כלשהו, מה ההסתברות שיצאו $k$ עצים?

	עבור ההטלה הראשונה, $\Omega_1 = \{0, 1\}$. עוד נגדיר $p(1) = \alpha, p(0) = 1 - \alpha$ עבור $0 \le \alpha \le 1$ כלשהו. \\*
	בהתאם נקבל $\Omega = {\{0, 1\}}^n$, וכן
	\[
		q(\omega_1, \dots, \omega_n) = \prod_{i = 1}^n p(\omega_i)
		= \prod_{i = 1}^n \alpha^{\omega_i} \cdot {(1 - \alpha)}^{1 - {\omega_i}}
		= \alpha^{\sum_{i = 1}^n \omega_i} {(1 - \alpha)}^{n - \sum_{i = 1}^n \omega_i}
	\]

	נבחין כי היינו יכולים לתאר את המקרה הזה ממש על־ידי $q(\omega) = \alpha^\omega \cdot {(1 - \alpha)}^{1 - \omega}$.

	נעבור עתה לבחינת המאורע
	\[
		A = \{ (\omega_1, \dots, \omega_n) \in \Omega \mid \sum_{i = 1}^{n} \omega_i = k \}
	\]
	נקבל מהביטוי שמצאנו כי
	\[
		\PP_q(A)
		= \sum_{(\omega_1, \dots, \omega_n) \in A} q(\omega_1, \dots, \omega_n)
		\sum_{\sum_{i = 1}^n \omega_i = k} \alpha^{\sum_{i = 1}^n \omega_i} {(1 - \alpha)}^{n - \sum_{i = 1}^n \omega_i}
		= |A| \alpha^k {(1 - \alpha)}^{n - k}
		= \binom{n}{k} \alpha^k {(1 - \alpha)}^{n - k}
	\]
\end{example}
\begin{example}
	נבחן עתה את המקרה של הטלות הוגנות ובחינת המקרה שחצי מההטלות לפחות יצאו עץ,
	זאת־אומרת שנבחן את הדוגמה הקודמת כאשר $n = 2m, k = m$, ו־$\alpha = \frac{1}{2}$.
	מנוסחת סטרלינג שאנחנו לא מכירים $m! \simeq \sqrt{2\pi m} {(\frac{m}{e})}^m$ ואז נוכל להסיק
	\[
		\PP_q(A)
		= \binom{2m}{m} \frac{1}{2^m}
		\simeq \frac{\sqrt{4\pi m} {(\frac{2m}{e})}^{2m}}{{(\sqrt{2\pi m} {(\frac{k}{e})}^m)}^2 2^{2m}}
		= \frac{\sqrt{4\pi m}}{2\pi m}
		= \frac{1}{\sqrt{\pi m}}
	\]
\end{example}

\subsection{ניסויים דו־שלביים}
נניח $(\Omega_1, \mathcal{F}_1, \PP_{p_1})$ מרחב הסתברות בדידה עבור הניסוי הראשון, ונניח שיש מרחב הסתברות בדידה עבור הניסוי השני כך שלכל תוצאה בניסוי הראשון, פונקציית ההסתברות תשתנה בהתאם בניסוי השני.
לכל $\omega_1 \in \Omega_1$ יש פונקציית הסתברות נקודתית $p_{\omega_1} : \Omega_2 \to [0, \infty)$.
נגדיר את מרחב הניסוי הדו־שלבי $(\Omega_1 \times \Omega_2, \mathcal{F}_{1, 2}, \PP_q)$,
כאשר $q(\omega_1, \omega_2) = p_1(\omega_1) \cdot p_{\omega_1}(\omega_2)$.
\begin{proposition}
	$\PP_q$ פונקציית הסתברות.
\end{proposition}
\begin{proof}
	\[
		\sum_{(\omega_1, \omega_2) \in \Omega_1 \times \Omega_2} q(\omega_1, \omega_2)
		= \sum_{\omega_1 \in \Omega_1} \left( \sum_{\omega_2 \in \Omega_2} p_1(\omega_1) p_{\omega_1}(\omega_2) \right)
		= \sum_{\omega_1 \in \Omega_1} p_1(\omega_1) \left( \sum_{\omega_2 \in \Omega_2} p_{\omega_1}(\omega_2) \right)
		= \sum_{\omega_1 \in \Omega_1} p_1(\omega_1)
		= 1
	\]
\end{proof}
\begin{example}
	$\Omega_1 = \{H, T\}$ ו־$\Omega_2 = \{1, \dots, 8\}$, נגדיר $p_1(H) = p_1(T) = \frac{1}{2}$.
	עוד נגדיר
	\[
		p_H(\omega_2) = \begin{cases}
			\frac{1}{6} & 1 \le \omega_2 \le 6 \\
			0 & \text{else}
		\end{cases},
		\qquad
		p_T(\omega_2) = \frac{1}{8}
	\]
	מהגדרה זו נקבל
	\[
		q(\omega_1, \omega_2) = \begin{cases}
			\frac{1}{12} & \omega_1 = H, \omega_2 \in [6] \\
			0 & \omega_1 = H, \omega_2 \in \{7, 8\} \\
			\frac{1}{16} & \omega_1 = T, \omega_2 \in [8]
		\end{cases}
	\]
\end{example}
\begin{theorem}[חסם האיחוד]
	אם $A, B$ מאורעות אז $\PP(A \cup B) \le \PP(A) + \PP(B)$.
\end{theorem}
\begin{proof}
	\[
		\PP(A \cup B)
		= \PP(A \uplus (B \setminus A))
		= \PP(A) + \PP(B \setminus A)
		\le \PP(A) + \PP(B)
	\]
\end{proof}
נוכל להשתמש בחסם האיחוד כדי להוכיח גרסה כללית יותר של המשפט:
\begin{theorem}[אי־שוויון בול]
	אם $A_1, \dots, A_k$ מאורעות, אז $\PP(\bigcup_{i = 1}^k A_i) \le \sum_{i = 1}^k \PP(A_i)$.
\end{theorem}
\begin{example}
	נחזור לבחון את פרדוקס יום ההולדת, הפעם נבחן גרסה כללית יותר של הרעיון.
	נגדיר $\Omega = {[m]}^k$ עם הסתברות אחידה.
	נגדיר גם $A = \{ \omega \in \Omega \mid \exists 1 \le i < j \le k, \omega_i = \omega_j \}$.
	אנו רוצים את ההסתברות $\PP(A) = \frac{|A|}{|\Omega|}$, אז נבחן את המשלים
	\[
		A^C = \{ \omega \in \Omega \mid \forall 1 \le i, j \le k, i \ne j \implies \omega_i \ne \omega_j \}
	\]
	נחשב
	\[
		|A^C| = m (m - 1) \cdots (m - (k - 1))
	\]
	בהתאם
	\[
		\PP(A^C)
		= \frac{\prod_{i = 0}^{k - 1} (m - i)}{m^k}
		= \prod_{i = 0}^{k - 1} \frac{m - i}{m^k}
		= \prod_{i = 0}^{k - 1} (1 - \frac{i}{m})
	\]
	נזכור ש־$\forall x \in \RR, 1 + x \le e^x$, ונוכל לקבל
	\[
		\prod_{i = 0}^{k - 1} (1 - \frac{i}{m})
		\le \prod_{i = 0}^{k - 1} e^{-\frac{i}{m}}
		= \exp(- \frac{1}{m} \sum_{i = 0}^{k - 1} i)
		= e^{- \frac{k(k - 1)}{2m}}
	\]
	כאשר $k$ גדול ביחס ל־$\sqrt{2m}$ מקבלים חסם קרוב ל־$0$.

נגדיר הפעם $A = \bigcup_{\substack{i \ne j \\ i, j \in [k]}} A_{ij}$ עבור $A_{ij} = \{ \omega \in \Omega \mid \omega_i = \omega_j \}$.
	וגם
	\[
		i \ne j \implies \PP(A_{ij}) = \frac{|A_{ij}|}{m^k} = \frac{m \cdot m^{k - 2}}{m^k} = \frac{1}{m}
	\]
	ועתה
	\[
		\PP(A)
		\le \sum_{\substack{i \ne j \\ i, j \in [k]}} \PP(A_{ij})
		= \sum_{\substack{i \ne j \\ i, j \in [k]}} \frac{1}{m}
		= \binom{k}{2} \frac{1}{m}
		= \frac{k (k - 1)}{2m}
	\]
	לכן אם $k$ קטן ביחס ל־$\sqrt{2m}$ אז ההסתברות ליום־הולדת משותף קטנה.
\end{example}

\section{תרגול 2 --- 7.11.2024}

\subsection{פתרון שאלות הסתברותיות}
נתחיל בבחינת טענה שימושית לביצוע חישובי הסתברות:
\begin{proposition}[נוסחת ההסתברות השלמה]
	יהי $(\Omega, \mathcal{F}, \PP)$ מרחב הסתברות, $\mathcal{A}$ חלוקה בת־מניה של $\Omega$, לכל $B \in \mathcal{F}$ מתקיים
	\[
		\PP(B) = \sum_{A \in \mathcal{A}} \PP(A \cap B)
	\]
	נניח שיש מרחב הסתברות ויש חלוקה בת מניה של המרחב, אז לכל מאורע ההסתברות שלו היא הסכום על החלוקה על החיתוך של החלוקה ו־$A$.
\end{proposition}
\begin{proof}
	נשים לב כי $B = \biguplus{A \in \mathcal{A}} B \cap A$ איחוד זר, ולכן הטענה נובעת מסיגמא־אדיטיביות.
\end{proof}
\begin{exercise}
	קוביה מוטה בעלת 6 פאות עם הסתברות נקודתית $p(i) = \frac{i}{21}$ מוטלת 5 פעמים. \\*
	מה ההסתברות שתוצאת ההטלה הראשונה התקבלה פעם אחת ויחידה?
\end{exercise}
\begin{solution}
	נגדיר $\Omega = {[6]}^5$ ונגדיר $\PP(x_1, \dots, x_5) = p(x_1) \cdots p(x_5)$.
	אנו רוצים לחשב את
	\[
		B = \{ (x_1, \dots, x_5) \in \Omega \mid \forall j \ne 1, x_j \ne x_1 \}
	\]
	נגדיר חלוקה $\mathcal{A} = \{ A_1, \dots, A_6 \}$ של $\Omega$ כך ש־$A_i = \{ (i, x_2, \dots, x_5) \in \Omega \mid 1 \le x_j \le 6 \}$. \\*
	נקבל
	\[
		\PP(B \cap A_i) = \frac{i}{21} \cdot {(1 - \frac{i}{21})}^4
	\]
	על־ידי שימוש בנוסחת ההסתברות השלמה נקבל
	\[
		\PP(B) = \sum_{i = 1}^{6} \PP(B \cap A_i) = \sum_{i = 1}^{6} \frac{i}{21} {(1 - \frac{i}{21})}^4
	\]
\end{solution}
נראה עתה דוגמה לשימוש בחסם האיחוד בן־המניה, אותו נראה בהרצאה הבאה
\begin{proposition}[חסם האיחוד הבן־מניה]
	אם $(\Omega, \mathcal{F}, \PP)$ מרחב הסתברות ו־${\{A_i\}}_{i = 1}^\infty \subseteq \mathcal{F}$ אז מתקיים
	\[
		\PP(\bigcup_{i = 1}^\infty A_i) \le \sum_{i \in \NN} \PP(A_i)
	\]
\end{proposition}
\begin{exercise}
	משלשלים $k$ פתקי הצבעה בין $n$ קלפיות. \\*
	מה ההסתברות שאין קלפי עם יותר מפתק אחד?
\end{exercise}
\begin{solution}
	נגדיר $\Omega = \{ (x_1, \dots, x_n) \mid 0 \le x_i, x_1 + \cdots + x_n = k \}$.
	נחשב ונקבל $|\Omega| = \binom{n + k - 1}{k - 1}$. \\*
	נגדיר את המאורע, $A = \{ (x_1, \dots, x_n) \in \Omega \mid x_i \le 1 \}$. \\*
	ננסה לחסום את המשלים,
	\[
		\Omega \setminus A = \{ (x_1, \dots, x_n) \in \Omega \mid \exists i, x_i \ge 2 \}
	\]
	אם נגדיר $A_i = \{ (x_1, \dots, x_n) \in \Omega \mid x_i \ge 2 \}$ אז נוכל להגדיר
	\[
		\Omega \setminus A = \bigcup_{i \in [n]} A_i
	\]
	נחשב את ההסתברות של כל $A_i$, מתקבל $|A_i| = \binom{n + k - 3}{k - 3}$ מהשיקול של סכימת הפתרונות השלמים תוך התעלמות משני פתקים. \\*
	לכן
	\[
		\PP(A_i) = \frac{|A_i|}{|\Omega|} = \frac{\binom{n + k - 3}{k - 3}}{\binom{n + k - 1}{k - 1}} = \frac{k(k - 1)}{(k + n - 1)(k + n - 2)}
	\]
	מחסם האיחוד נובע
	\[
		\PP(\Omega - A) \le \sum_{i = 1}^{n} \frac{k(k - 1)}{(k + n - 1)(k + n - 2)} = n \cdot \frac{k(k  -1)}{(n + k - 1)(n + k - 2)}
	\]
	ועל־ידי מעבר למשלים שוב נוכל להסיק $\PP(A) \ge 1 - n \cdot \frac{k(k  -1)}{(n + k - 1)(n + k - 2)}$. \\*
	נזכור כי אנו מנסים להבין את המגמה כאשר המספרים מאוד גדולים, לכן נבחן את המקרה ש־$n \to \infty$, אז נובע $\PP(A) \xrightarrow[n \to \infty]{} 1$, \\*
	דהינו כאשר יש כמות קלפיות הולכת וגדלה הסיכוי שיהיה פתק יחיד בכל אחת (מספר הפתקים לא משתנה) הולך וגדל ומתקרב לסיכוי מלא.
\end{solution}
נראה עתה דוגמה לשימוש במרחבי ניסוי דו־שלביים:
\begin{exercise}
	מה ההסתברות שנגריל מספר $m$ בין $1$ ל־$n$,
	ואז נגריל עוד מספר והוא יהיה בין $1$ לבין $m$?
\end{exercise}
\begin{solution}
	נבנה פונקציית הסתברות עבור הניסוי השני, נניח שבניסוי השני קיבלנו $m$:
	\[
		p_m(k) = \begin{cases}
			\frac{1}{m} & k \le m \\
			0 & k > m
		\end{cases},
		\qquad
		q(m, k) = \begin{cases}
			\frac{1}{mn} & k \le m \\
			0 & k > m
		\end{cases}
	\]
	נגדיר $A_k$ המאורע שתוצאת ההגרלה השניה היא $k$, לכן
	\[
		\PP(A_k)
		= \PP(\{(m, k) \in \Omega \mid m \le k \})
		= \sum_{m = 1}^{n} q(m, k)
		= \sum_{m = k}^{n} \frac{1}{mn}
	\]
	נבחין כי המעבר האחרון אכן תקין, שכן קיבענו את המשתנה השני, זאת אומרת שעכשיו במקום להסתכל על מספר שיותר קטן ממספר אחר, אנו בוחנים את המספר החוסם מלמעלה, המספר הגדול יותר. \\*
	לדוגמה
	\[
		\PP(A_n) = \frac{1}{n^2},
		\qquad
		\PP(A_1) = \sum_{m = 1}^{n} \frac{1}{mn} = \frac{1}{n} \sum_{m = 1}^n \frac{1}{m} \approx \frac{\log n}{n}
	\]
\end{solution}
נבחן דוגמה ספציפית כהמשך של השאלה הזו, הפעם נגדיר $m = n / 2$:
\begin{example}
	נגדיר $B_{n / 2}$ להיות המאורע בהתחלה השניה ו־$B$ שבהגרלה השניה יצא מספר גדול מ־$n / 2$
	\[
		\PP(B_{n / 2}) = \PP(\bigcup_{k \ge n / 2}^n A_k)
		= \frac{1}{n} \sum_{k \ge \frac{n}{2}}^n \sum_{m = k}^n \frac{1}{m}
		= \frac{1}{n} \sum_{m = \lceil \frac{n}{2}\rceil}^{n} \frac{\frac{n}{2} + 1 - n + m}{m}
	\]
	כמו בשאלה הקודמת, גם הפעם נרצה להבין מגמה כללית, ולכן נבדוק את הביטוי כאשר $n$ שואף לאינסוף, דהינו שהמספרים שאפשר להגדיל הולכים וגדלים בכמותם:
	\[
		\lim_{n \to \infty} \PP(B_{n / 2})
		= \lim_{n \to \infty} \frac{1}{n} \sum_{m = \lceil \frac{n}{2}\rceil}^{n} \frac{1 + m - \frac{n}{2}}{m}
	\]
	נבחין כי $\sum_{m = 1}^n \frac{1}{m} = \log(n) + e + o(\frac{1}{m})$ ולכן
	\begin{align*}
		\lim_{n \to \infty} \frac{1}{n} \sum_{m = \lceil \frac{n}{2}\rceil}^{n} \frac{1 + m - \frac{n}{2}}{m}
		& = \lim_{n \to \infty} \frac{1}{2} + \frac{n}{2n} (\log(n) - \log(\frac{n}{2}) + o(\frac{1}{n})) + \frac{1}{n} (\log(n) - \log(\frac{n}{2}) + o(\frac{1}{n})) \\
		& = \frac{1}{2} + \frac{1}{n} \log 2
	\end{align*}
\end{example}

\section{שיעור 4 --- 7.11.2024}
בשיעור הקודם דיברנו על מרחבי מכפלה וניסויים דו־שלביים.
ברור לנו כי על־ידי שרשור דומה לתהליך של ניסוי דו־שלבי נוכל לבנות ניסוי רב־שלבי.
עוד דיברנו על חסם האיחוד, הטענה כי $\PP(\bigcup_{i = 1}^n A_i) = \sum_{i = 1}^n \PP(A_i)$.
השימוש של חסם האיחוד מאפשר לנו לפשט חישובים שבהם אנחנו רוצים הבנה כללית של ההתנהגות של מרחב ההסתברות.

\subsection{חסמי איחוד ורציפות}
\begin{definition}[סדרת מאורעות עולה]
	סדרת מאורעות ${\{A_n\}}_{n = 1}^\infty$ נקראת עולה אם $A_n \subseteq A_{n + 1}$ לכל $n \in \NN$.
\end{definition}
\begin{notation}
	נסמן $A_\infty = \bigcup_{n \in \NN} A_n$.
\end{notation}
\begin{theorem}[משפט רציפות פונקציית ההסתברות]
	אם ${\{A_n\}}_{n = 1}^\infty$ סדרת מאורעות עולה אז
	\[
		\PP(A_\infty) = \lim_{n \to \infty} \PP(A_n)
	\]
\end{theorem}
המשפט נקרא כך בשל ההקבלה שלו לקונספט של רציפות בפונקציות רגילות, עבור $f : \RR \to \RR$ היא רציפה ב־$a$ אם ורק אם לכל סדרה $x_n \to a$ מתקיים $f(x_n) \to f(a)$.
\begin{proof}
	נגדיר $B_n = A_n \setminus A_{n - 1}$ כאשר $B_1 = A_1 \setminus \emptyset = A_1$. \\*
	נראה כי מתקיים $\biguplus_{n = 1}^m B_n = A_m$ איחוד זר: \\*
	$\bigcup_{n = 1}^m B_n = A_m$ כי לכל $\omega \in A_m$ יש $n$ מינימלי כך ש־$\omega \in A_n$, אבל $\omega \notin A_{n - 1}$, לכן נוכל להסיק כי $\omega \in A_n \setminus A_{n - 1} = B_n$. \\*
	אם $\omega \in B_n = A_n \setminus A_{n - 1}$ אז $\omega \notin A_{n - 1}$ ולכן $\omega \notin A_k$ לכל $k < n$.
	מסיגמא־אדיטיביות נסיק
	\[
		\sum_{n = 1}^{m} \PP(B_n) = \PP(A_m)
	\]
	וגם
	\[
		\sum_{n = 1}^{\infty} \PP(B_n)
		= \PP(\biguplus_{n = 1}^\infty B_n)
		= \PP(\bigcup_{m = 1}^\infty \left(\biguplus_{n = 1}^\infty B_n\right))
		= \PP(\bigcup_{m = 1}^\infty A_m)
	\]
	מצד שני מהגדרת הגבול
	\[
		\sum_{n = 1}^{\infty} \PP(B_n)
		= \lim_{m \to \infty} \sum_{n = 1}^{m}  \PP(B_n)
		= \lim_{m \to \infty} \PP(A_m)
	\]
\end{proof}
\begin{definition}[סדרת מאורעות יורדת]
	נגדיר סדרת מאורעות ${\{A_n\}}_{n = 1}^\infty$ כך שמתקיים $A_{n + 1} \subseteq A_n$ לכל $n \in \NN$.
\end{definition}
נוכל להסיק מהעובדה שמשלים של סדרה עולה הוא סדרה יורדת ונקבל
\begin{proposition}
	\[
		\PP(\bigcap_{n \in \NN} A_n) = \lim_{n \to \infty} \PP(A_n)
	\]
\end{proposition}
\begin{proposition}[חסם האיחוד הבן־מניה]
	אם ${\{A_n\}}_{n = 1}^\infty$ סדרת מאורעות אז מתקיים
	\[
		\PP(\bigcup_{n = 1}^\infty A_n) \le \sum_{n \in \NN} \PP(A_n)
	\]
\end{proposition}
\begin{proof}
	נגדיר $B_m = \bigcup_{n = 1}^m A_n$, זוהי סדרה עולה ולכן
	\[
		\PP(\bigcup_{n = 1}^\infty A_n)
		= \PP(\bigcup_{m = 1}^\infty B_m)
		= \lim_{m \to \infty} \PP(B_m)
		\le \lim_{m \to \infty} \sum_{n = 1}^{m} \PP(A_n)
		= \sum_{n = 1}^{\infty} \PP(A_n)
	\]
\end{proof}

\subsection{עיקרון ההכלה וההדחה}
\begin{proposition}
	אם $A, B$ מאורעות אז
	\[
		\PP(A \cup B) = \PP(A) + \PP(B) - \PP(A \cap B)
	\]
\end{proposition}
\begin{proof}
	נגדיר $C = A \setminus B, D = A \cap B, E = B \setminus A$, נקבל
	\[
		A = C \uplus D,
		\quad
		B = D \uplus E,
		\quad
		A \cup B = C \uplus D \uplus E
	\]
	ונקבל
	\[
		\PP(A) = \PP(C) + \PP(D),
		\quad
		\PP(D \cup B) = \PP(D) + \PP(E)
	\]
	ולכן
	\[
		\PP(A \cup B) = \PP(C) + \PP(D) + \PP(E)
	\]
\end{proof}
\begin{theorem}[הכלה והפרדה לשלושה מאורעות]
	עבור שלושה מאורעות $A, B, C$:
	\[
		\PP(A \cup B \cup C) = \PP(A) + \PP(B) + \PP(C) - (\PP(A \cap B) + \PP(A \cap C) + \PP(B \cap C)) + \PP(A \cap B \cap C)
	\]
\end{theorem}
\begin{theorem}[הכלה והפרדה ל־n מאורעות]
	יהיו $A_1, \dots, A_n$ מאורעות, אז
	\[
		\PP(\bigcup_{i = 1}^n A_i)
		= \sum_{i = 1}^{n} \PP(A_i) - \sum_{i = 1}^{n} \sum_{j = 1}^{i - 1} \PP(A_i \cap A_j) + \sum_{i = 1}^{n} \sum_{j = 1}^{i - 1} \sum_{k = 1}^{j - 1} \PP(A_i \cap A_j \cap A_k) + \dots
	\]
	אם נגדיר $A_I = \bigcap_{i \in I} A_i$ לכל $I \subseteq [n]$ אז נקבל
	\[
		\PP(\bigcup_{n = 1}^n A_i)
		= \sum_{k = 1}^{n} {(-1)}^{k + 1} \sum_{\substack{I \subseteq [i] \\ |I| = k}} \PP(A_I)
		= \sum_{\emptyset \ne I \subseteq [n]} {(-1)}^{|I| + 1} \PP(A_I)
	\]
\end{theorem}
את משפט זה נוכיח בהמשך הקורס. \\*
נראה דוגמה לבעיה קלאסית במקרים אלה.
\begin{exercise}[בעיית ההתאמה]
	מחלקים $n$ מעטפות ל־$n$ תיבות דואר, אחת לכל תיבה, מה ההסתברות שאף מכתב לא הגיע ליעדו?
\end{exercise}
\begin{solution}
	נגדיר $\Omega = S_n$ מרחב אחיד.
	$A = \{ \omega \in \Omega \mid \forall i, \omega(i) \ne i \}$. \\*
	נבחן את המשלים, $A^C = \{ \omega \in \Omega \mid \exists i, \omega(i) = i \} = \bigcup_{i = 1}^n A_i$ עבור $A_i = \{ \omega \in \Omega \mid \omega(i) = i \}$.
	נחשב
	\[
		\PP(A_i) = \frac{|A_i|}{|\Omega|} = \frac{(n - 1)!}{n!} = \frac{1}{n}
	\]
	במקרה של חיתוך $\PP(A_i \cap A_j)$ עבור $j < i$ נקבל
	\[
		\PP(A_i \cap A_j) = \frac{|A_i \cap A_j|}{|\Omega|} = \frac{(n - 2)!}{n!} = \frac{1}{n(n - 1)}
	\]
	נוכל להמשיך את התהליך הזה, ונקבל
	\[
		\PP(A_I) = \frac{|\bigcap_{i \in I} A_i|}{|\Omega|}
		= \frac{(n - |I|)!}{n!}
		= \frac{1}{n (n - 1) (n - 2) \cdots (n - (I + 1))}
	\]
	כעת נותר להשתמש בנוסחה להכלה והדחה, ונקבל
	\[
		\PP(\bigcup_{i = 1}^n A_i)
		= \sum_{k = 1}^{n} {(-1)}^{k + 1} \sum_{\substack{I \subseteq [n] \\ |I| = k}} \frac{(n - k)!}{n!}
		= \sum_{k = 1}^{n} {(-1)}^{k + 1} \binom{n}{k} \frac{(n - k)!}{n!}
		= \sum_{k = 1}^{n} \frac{{(-1)}^{k + 1}}{k!}
	\]
	נשים לב כי רצינו לחשב את המשלים למאורע, לכן
	\[
		\PP(A)
		= 1 - \PP(\bigcup_{i = 1}^n A_i)
		= 1 + \sum_{k = 1}^{n} \frac{{(-1)}^k}{k!}
		= \sum_{k = 0}^{n} \frac{{(-1)}^k}{k!}
		\xrightarrow[n \to \infty]{} e^{-1}
	\]
	נקבל שאוסף התמורות ללא נקודת שבת הוא
	\[
		|A^n| = n! \sum_{l = 0}^{n} \frac{{(-1)}^l}{l!}
	\]
	נגדיר קבוצה חדשה
	\[
		D_k = \{ \omega \in S_n \mid \exists i, \omega(i) = i \}
		= \biguplus_{\substack{I \subseteq [n] \\ |I| = k }} D_I
	\]
	ונבחין כי
	\[
		D_I = \{ \omega \in S_n \mid \forall i \in I, \omega(i) = i, \forall i \notin I, \omega(i) \ne i \}
	\]
	ולכן
	\begin{align*}
		\PP(D_k)
		& = \sum_{\substack{I \subseteq [n] \\ |I| = k }} \PP(D_I) \\
		& = \sum_{\substack{I \subseteq [n] \\ |I| = k }} \frac{|D_I|}{n!} \\
		& = \sum_{\substack{I \subseteq [n] \\ |I| = k }} \frac{(n - k)! \sum_{l = 0}^n \frac{{(-1)}^l}{l!}}{n!} \\
		& = \binom{n}{k} \frac{(n - k)!}{n!} \sum_{l = 0}^n \frac{{(-1)}^l}{l!} \\
		& = \frac{1}{k!} \sum_{l = 0}^n \frac{{(-1)}^l}{l!} \\
		& \xrightarrow[n \to \infty]{} \frac{e^{-1}}{k!}
	\end{align*}
\end{solution}

\section{שיעור 5 --- 12.11.2024}

\subsection{הסתברות מותנית}
\begin{definition}[הסתברות מותנית]
	$A, B$ מאורעות, ההסתברות המותנית של $A$ בהינתן $B$ תוגדר להיות
	\[
		\PP(A \mid B) = \frac{\PP(A \cap B)}{\PP(B)}
	\]
\end{definition}
\begin{example}
	אם מטילים שתי קוביות מאוזנות, מה ההסתברות שיצא 3 בקוביה הראשונה בהינתן שהסכום הוא 8?

	נגדיר כמובן $\Omega = {[6]}^2$, וכן נגדיר $A = \{ (3, i) \in \omega \mid 1 \le i \le 6 \}$ וכן $B = \{ (2, 6), (3, 5), (4, 4), (5, 3), (6, 2) \}$.
	\[
		\PP(A \mid B) = \frac{\PP(A \cap B)}{\PP(B)}
		= \frac{\frac{1}{36}}{\frac{5}{36}}
		= \frac{1}{5}
	\]
\end{example}
\begin{proposition}
	נקבע מאורע $B$ עם הסתברות $\PP(B) > 0$, נגדיר $\PP_B(A) = \PP(A \mid B)$, דהינו $\PP_B : \mathcal{F} \to [0, \infty)$. \\*
	אז $\PP_B$ היא פונקציית הסתברות.
\end{proposition}
\begin{proof}
	$\PP_B(A)$ היא אי־שלילית. \\*
	נראה גם
	\[
		\PP_B(\Omega) = \frac{\PP(\Omega \cap B)}{\PP(B)} = 1
	\]
	ולבסוף
	\[
		\PP_B(\biguplus_{i \in I} A_i)
		= \frac{(\PP_B(\biguplus_{i \in I} A_i )) \cap B}{\PP(B)}
		= \frac{\PP_B(\biguplus_{i \in I} A_i \cap B)}{\PP(B)}
		= \sum_{i \in I} \frac{\PP(A_i \cap B)}{\PP(B)}
		= \sum_{i \in I} \PP_B(A_i)
	\]
\end{proof}
\begin{proposition}
	יהיו $C, B$ מאורעות המקיימים $\PP(B \cap C) > 0$, נסמן $\PP' = \PP_B$ ו־$\PP'' = \PP_C'$. \\*
	אז לכל מאורע $A$ מתקיים $\PP''(A) = \PP(A \mid B \cap C)$ או בחילוף סימונים $\PP'' = \PP_{B \cap C}$.
\end{proposition}
\begin{proof}
	\[
		\PP''(A)
		= \PP_C'(A)
		= \frac{\PP'(A \cap C)}{\PP'(C)}
		= \frac{\PP_B(A \cap C)}{\PP_B(C)}
		= \frac{\frac{\PP(B \cap (A \cap C))}{\PP(B)}}{\frac{\PP(B \cap C)}{\PP(B)}}
		= \PP_{B \cap C}(A)
	\]
\end{proof}
מצאנו כי התניה חוזרת היא אסוציאטיבית ולכן נוכל לדבר על הסתברות מותנית בכמה מאורעות ללא התייחסות לסדר שלהם, למעשה התנייה מותנית היא קומוטטיבית כפי שאפשר לראות בהוכחה.
\begin{conclusion}[נוסחת ההסתברות השלמה בהסתברות מותנית]
	נניח ש־${\{A_i\}}_{i \in \NN}$ חלוקה בת־מניה של $\Omega$ ו־$B$ מאורע כלשהו, אז
	\[
		\PP(B) = \sum_{i \in \NN} \PP(A_i) \PP(B \mid A_i)
	\]
\end{conclusion}
\begin{proof}
	\[
		\PP(A_i) \PP(B \mid A_i) = \PP(A_i) \frac{\PP(B \cap A_i)}{\PP(A_i)} = \PP(B \cap A_i)
	\]
	ולכן
	\[
		\biguplus_{i \in \NN} (B \cap A_i) = B
		\implies \PP(B) = \sum_{i \in \NN} \PP(B \cap A_i)
	\]
\end{proof}
\begin{lemma}[כלל בייס]
	אם $A, B$ מאורעות עם הסתברות חיובית אז
	\[
		\PP_A(B) = \frac{\PP(B)}{\PP(A)} \PP_B(A)
	\]
\end{lemma}
\begin{proof}
	ישירות מהגדרה נסיק
	\[
		\PP_A(B)
		= \frac{\PP(A \cap B)}{\PP(A)}
		= \frac{\PP(B)}{\PP(A)} \cdot \frac{\PP(A \cap B)}{\PP(B)}
		= \frac{\PP(B)}{\PP(A)} \PP_B(A)
	\]
\end{proof}
\begin{conclusion}[כלל השרשרת]
	\[
		\PP(A \cap B) = \PP(A) \PP(B \mid A)
	\]
\end{conclusion}
\begin{exercise}
	מטילים מטבע הוגן. אם יוצא עץ נוסעים לתל־אביב ואם יוצא פלי אז ונסעים לחיפה.
	כשנוסעים לתל־אביב יש הסתברות של אחוז אחד לפנצ'ר, ובנסיעה לחיפה יש הסתברות של 2 אחוז לפנצ'ר. \\*
	מה ההסתברות לפנצ'ר ומה ההסתברות שנסעו לתל־אביב?
\end{exercise}
\begin{solution}
	נגדיר $A$ הוא עץ או לנסוע לתל־אביב ו־$B$ ההסתרות שיהיה פנצ'ר, בהתאם
	\[
		\PP(A^C) = \PP(A) = \frac{1}{2},
		\qquad
		\PP(B \mid A) = 0.01,
		\PP(B \mid A^C) = 0.02
	\]
	בהתאם
	\[
		\PP(B) = \PP(A) \PP(B \mid A) + \PP(A^C) + \PP(B \mid A^C)
		= \frac{1}{2} 0.01 + \frac{1}{2} 0.02 = 0.015
	\]
	באשר לשאלה השנייה נקבל
	\[
		\PP(A \mid B) = \frac{\PP(A \cap B)}{\PP(B)} = \frac{\PP(A)}{\PP(B)} \PP(B \mid A) = \frac{\frac{1}{2}}{0.015} \cdot 0.01 = \frac{1}{3}
	\]
\end{solution}
נבחין כי התוצאה יצאה מאוד אלגנטית כתוצאה מהמטבע ההוגן, אילו הוא היה לא הוגן היינו מקבלים חישוב שונה במקצת, אך תקף באותה המידה.
\begin{example}[מונטי הול]
	יש שלוש דלתות, בוחרים אחת, מנחה פותח דלת שלא נבחרה ומאחוריה אין כלום, מה שאומר שמאחורי אחת הדלתות הסגורות יש אוצר ובאחרות יש עז.
	המנחה מציע לכם להחליף את הדלת שבחרתם.

	קשה למדל את הבעיה הזו, שכן חסר תיאור והגדרה, אז נאמר שהגרלנו מספר ב־$[3]$, נניח שבחרנו $1$, נניח שהמנחה גם במכוון תמיד בוחר דלת ריקה.
	נוסיף את ההנחה שאם האוצר מאחורי דלת 1 אז המנחה פותח את 2 או 3, וההסתברויות שוות.
	
	נעבור להגדרה, $A_i$ המאורע שהאוצר ב־$i$ ו־$B_i$ היא שהמנחה פותח את דלת $i$.
	מההנחות שלנו נובע $\PP(B_3 \mid A_2) = 1, \PP(B_2 \mid A_3) = 1, \PP(B_3 \mid A_1) = \PP(B_2 \mid A_1) = \frac{1}{2}$.
	לבסוף נניח כי $\PP(A_i) = \frac{1}{3}$ לכל שלוש הדלתות. \\*
	נרצה לחשב את $\PP(A_1 \mid B_2)$:
	\[
		\PP(A_1 \mid B_2)
		= \frac{\PP(A_1)}{\PP(B_2)} \cdot \PP(B_2 \mid A_1)
		= \frac{\frac{1}{6}}{\PP(B_2)}
	\]
	וגם
	\[
		\PP(B_2) = \PP(A_1) \PP(B_2 \mid A_1) + \PP(A_2) \PP(B_2 \mid A_2) + \PP(A_3) \PP(B_2 \mid A_3) = \frac{1}{3} \cdot \frac{1}{2} + \frac{1}{3} \cdot 0 + \frac{1}{3} \cdot 1 = \frac{1}{2}
	\]
\end{example}

\section{תרגול 3 --- 14.11.2024}

\subsection{הסתברות מותנית}
\begin{exercise}
	מטילים זוג קוביות הוגנות ושונות. נתון שסכום תוצאותיהן גדול מעשר,
	מה ההסתברות שבהטלה השנייה יצא 6?
\end{exercise}
\begin{solution}
	נגדיר $\Omega = {[6]}^2$ עם $\PP$ אחידה. \\*
	עוד נגדיר $A = \{ (x, y) \in \Omega \mid x + y > 10 \}$ וכן $B = \{ (x, 6) \in \Omega \}$, לכן
	\[
		\PP(B \mid A)
		= \frac{\PP(A \cap B)}{\PP(A)}
		= \frac{\frac{|A \cap B|}{|\Omega|}}{\frac{|A|}{|\Omega|}}
		= \frac{|A \cap B|}{|A|} = \frac{2}{3}
	\]
\end{solution}
\begin{exercise}
	אדם מחפש מכתב, זכור לו במעורפל בהסתברות $0 \le p \le 1$ שהניח אותו באחת ממגירות שולחן העבודה. \\*
	בשולחן $n$ מגירות והאדם חיפש ב־$k$ המגירות הראשונות ולא מצא את המכתב. \\*
	מה ההסתברות שהמכתב בשולחן?
\end{exercise}
\begin{solution}
	נגדיר $A$ להיות המאורע שהמכתב בשולחן ו־$B_k$ המכתב לא באף אחת מ־$k$ המגירות הראשונות. אנו מחפשים את $\PP(A \mid B_k)$. \\*
	לכן
	\[
		\PP(A \mid B_k)
		= \frac{\PP(A \cap B_k)}{\PP(B_k)}
	\]
	עוד אנו יודעים כי
	\[
		\PP(A) = p,
		\PP(B_k) = 1 - \frac{kp}{n}
	\]
	אזי
	\[
		\frac{\PP(A \cap B_k)}{\PP(B_k)}
		= \frac{\frac{(n - k)p}{n}}{\frac{n - kp}{n}}
		= \frac{(n - k) p}{n - kp}
	\]
\end{solution}
\begin{exercise}
	האדם הוא מתודי והחליט להפסיק את החיפוש אם ההסתברות שהמכתב בשולחן קטנה מ־$\frac{1}{4}$. \\*
	נניח ש־$p = \frac{3}{4}$ ושיש 10 מגירות, כמה מגירות תיבדקנה לכל היותר עד שהאדם יפסיק את החיפוש?
\end{exercise}
\begin{solution}
	\[
		\frac{1}{4} > \PP(A \mid B_k) = \frac{(10 - k) \frac{3}{4}}{10 - \frac{3k}{4}} \iff k > \frac{89}{11}
	\]
	נבדוק לכל היותר 8 מגירות.
\end{solution}

\subsection{ניסוי דו־שלבי על־ידי הסתברות מותנית}
\begin{proposition}
	נניח שנתון ניסוי דו־שלבי על $\Omega_1 \times \Omega_2$ עם פונקציית הסתברות נקודתית $p$ על $\Omega_1$ ולכל $\omega \in \Omega_1$ גם $p_\omega$ היא פונקציית הסתברות נקודתית על $\Omega_2$. \\*
	אם $\PP$ היא פונקציה על $\Omega_1 \times \Omega_2$ המקיימת
	\[
		\PP(\{a, x\}) = p(a),
		\qquad
		\PP(\{ x, b \} \mid \{ (a, x) \}) = p_a(b)
	\]
	אז $\PP$ היא פונקציית הסתברות יחידה המתאימה לניסוי הדו־שלבי.
\end{proposition}
\begin{proof}
	יהי $(a, b) \in \Omega_1 \times \Omega_2$, מכלל השרשרת נובע
	\[
		\PP(\{(a, b)\})
		= \PP(\{(a, x)\}) \cdot \PP(\{(x, b)\} \mid \{(a, x)\})
		= p(a) \cdot p_a(b)
		= q(a, b)
	\]
	עבור $q$ פונקציית הסתברות נקודתית של $\PP$.
\end{proof}
נבחין שוב כי בעוד כל ניסוי דו־שלבי, ניתן לבחון אותו כניסוי מותנה, הכיוון ההפוך לא בהכרח מתקיים; לא כל ניסוי מותנה הוא ניסוי דו־שלבי. \\*
נבחן דוגמות לשימוש בקשר זה.
\begin{exercise}
	בשוק ישנם שלושה סוגי מחשבים. חצי מסוג ראשון, 30\% מסוג שני ו־20\% מסוג שלישי. \\*
	הסיכוי שמחשב מסוג ראשון יתקלקל בשנתו הראשונה הוא עשירית, הסיכוי לסוג שני הוא חמישית והסיכוי למחשב מהסוג השלישי הוא $\frac{1}{20}$. \\*
	קונים מחשב באקראי מבין מחשבי השוק, מה ההסתברות שהוא יתקלקל בשנתו הראשונה?
\end{exercise}
\begin{solution}
	נסמן $C_j$ הוא המאורע שקנינו מחשב מסוג $j$ ו־$B$ המאורע שהמחשב התקלקל בשנתו הראשונה. \\*
	עוד נתון $\PP(C_1) = \frac{l}{2}, \PP(C_2) = \frac{3}{10}, \PP(C_3) = \frac{1}{5}$. \\*
	נתונים לנו גם $\PP(B \mid C_1) = \frac{1}{10}, \PP(B \mid C_2) = \frac{1}{5}, \PP(B \mid C_3) = \frac{1}{20}$.
	מנוסחת ההסתברות השלמה נובע
	\[
		\PP(B) = \PP(B \mid C_1) \PP(C_1) + \PP(B \mid C_2) \PP(C_2) + \PP(B \mid C_3) \PP(C_3)
	\]
\end{solution}
\begin{exercise}
	במבחן אמריקאי לכל שאלה 4 אפשרויות ובדיוק 1 נכונה.
	סטודנטית ניגשת למבחן עם האסטרטגיה הבאה:
	\begin{itemize}
		\item אם היא יודעת את התשובה היא עונה נכונה.
		\item אם היא לא יודעת את התשובה אז היא בוחרת תשובה אקראית.
	\end{itemize}
	נתון כי הסטודנטית יודעת את התשובה ל־90\% משאלות הבחינה. \\*
	בוחרים שאלה באקראי, ונתון שהסטודנטית ענתה עליה נכון, מה ההסתברות שהיא ידעה את התשובה.
\end{exercise}
\begin{solution}
	נסמן ב־$A$ את המאורע שהסטודנטית ידעה את התשובה, וב־$B$ את המאורע שהסטודנטית ענתה נכון. \\*
	אנו יודעים כי $\PP(A) = \frac{9}{10}$ וגם כי $\PP(B \mid A) = 1, \PP(B \mid A^C) = \frac{1}{4}$.
	\[
		\PP(A \mid B)
		= \frac{\PP(A)}{\PP(B)} \PP(B \mid A)
		= \frac{\frac{9}{10} \cdot 1}{\PP(B \mid A) \cdot \PP(A) + \PP(B \mid A^C) \cdot \PP(A^C)}
		= \frac{\frac{9}{10}}{\frac{9}{10} + \frac{1}{4} \cdot \frac{1}{10}}
		= \frac{\frac{9}{10}}{\frac{37}{40}}
		\approx 0.973
	\]
\end{solution}

\section{שיעור 6 --- 14.11.2024}

\subsection{אי־תלות}
\begin{definition}[מאורעות בלתי־תלויים]
	מאורעות $A, B$ המקיימים $\PP(A \cap B) = \PP(A) \PP(B)$ יקראו \textbf{בלתי־תלויים}.
\end{definition}
\begin{remark}
	נובע שמתקיים
	\[
		\PP(A \mid B) = \PP(A),
		\qquad
		\PP(B \mid A) = \PP(B)
	\]
\end{remark}
\begin{remark}[תזכורת]
	אם $A \subseteq \Omega_1$ ו־$B \subseteq \Omega_2$ ועובדים עם $\PP$ פונקציית הסתברות של מרחב המכפלה $\Omega_1 \times \Omega_2$. \\*
	אז ראינו שמתקיים $\PP(A \times B) = \PP_1(A) \cdot \PP_2(B) = \PP(A \times \Omega_2) \cdot \PP(\Omega_1 \times B)$
\end{remark}
\begin{example}
	מטילים שתי קוביות, אז $\Omega = {[6]}^2$. \\*
	נגדיר $A = \{ 4 \} \times [6]$ המאורע שיצא 4 בקוביה הראשונה ו־$B$ המאורע שסכום הקוביות הוא 7.
	\[
		\PP(A) = \frac{|A|}{|\Omega|} = \frac{1}{6},
		\qquad
		\PP(B) = \frac{|B|}{|\Omega|} = \frac{1}{6}
	\]
	וחישוב חיתוך המאורעות יניב
	\[
		\PP(A \cap B) = \frac{|A \cap B|}{|\Omega|} = \frac{|\{(4, 3)\}|}{36} = \frac{1}{36} = \PP(A) \PP(B)
	\]
	אז המאורעות בלתי־תלויים.
\end{example}
\begin{proposition}
	\begin{enumerate}
		\item לכל מאורע $A$, $A$ ו־$\emptyset$ בלתי־תלויים וכן $A$ ו־$\Omega$ בלתי־תלויים.
		\item אם $A$ ו־$B$ בלתי־תלויים ו־$\PP(B) > 0$ אז $\PP(A \mid B) = \PP(A)$.
		\item אם $A$ ו־$B$ בלתי־תלויים אז גם $A^C$ ו־$B$ בלתי תלויים.
	\end{enumerate}
\end{proposition}
\begin{proof}
	נוכיח את הטענה השלישית
	\[
		\PP(B \cap A^C)
		= \PP(B) - \PP(A \cap B)
		= \PP(B) - \PP(B) \PP(A)
		= \PP(B) (1 - \PP(A))
		= \PP(B) \PP(A^C)
	\]
	במעבר הראשון השתמשנו בנוסחת ההסתברות השלמה על החלוקה $A, A^C$.
\end{proof}
נראה הגדרה לאי־תלות במספר מאורעות, אך לא ההגדרה שאנו רוצים לעבוד איתה.
\begin{definition}[אי־תלות בזוגות]
	אם $A_1, \dots, A_n$ נקראים בלתי תלויים בזוגות אם
	\[
		\forall 1 \le i < j \le n, \PP(A_i \cap A_j) = \PP(A_i) \PP(A_j)
	\]
\end{definition}
\begin{definition}[קבוצה בלתי־תלויה]
	מאורע $A$ נקרא בלתי־תלוי בקבוצת המאורעות $B_1, \dots, B_n$ אם לכל $I \subseteq [n]$ מתקיים
	\[
		\PP(A \mid \bigcap_{i \in I} B_i) = \PP(A)
	\]
	דהינו $A$ ו־$\bigcap_{i \in I} B_i$ בלתי־תלוי.
\end{definition}
\begin{exercise}
	הביאו דוגמה למאורעות $A, B_1, B_2$ כך ש־$A$ ו־$B_1$ בלתי־תלויים וכך גם $A$ ו־$B_2$ אבל $A$ לא בלתי־תלוי בקבוצה $\{B_1, B_2\}$. \\*
	הראו כי אם $A, B_1$ בלתי־תלויים וגם $A, B_2$ בלתי־תלויים וגם $B_1, B_2$ זרים, אז $A$ בלתי־תלוי ב־$\{B_1, B_2\}$.
\end{exercise}
\begin{proposition}
	$A$ בלתי־תלוי ב־$\{B_1, \dots, B_n\}$ אם ורק אם $A$ בלתי תלוי ב־$\{B_1, \dots, B_n, B_1^C, \dots, B_n^C\}$.
\end{proposition}
\begin{proof}
	הכיוון השני הוא טריוויאלי, לכן נוכיח את הכיוון הראשון בלבד. \\*
	נראה ש־$A$ בלתי־תלוי בקבוצה ${\{B_1, \dots, B_n, B_1\}}^C$.
	נרצה להראות שלכל $I \subseteq [n + 1]$ מתקיים ש־$A$ ו־$\bigcap_{i \in I} B_i$ בלתי־תלויים. \\*
	אם $n + 1 \notin I$ אז לפי ההנחה חוסר התלות כבר מתקיים. \\*
	אחרת נגדיר $J = I \setminus \{ n + 1 \}$ ולכן $I = J \uplus \{ n + 1 \}$, ומכאן נובע
	\begin{align*}
		\PP((\bigcap_{i \in I} B_i) \cap A)
		& = \PP((\bigcap_{i \in J} B_i) \cap B_1^C \cap A) \\
		& = \PP(\bigcap_{i \in J} B_i \cap A) - \PP(\bigcap_{i \in J} B_i \cap B_1 \cap A) \\
		& = \PP(\bigcap_{i \in J} B_i) \PP(A) - \PP(\bigcap_{i \in J} B_i \cap B_1) \PP(A) \\
		& = \PP(\bigcap_{i \in J} B_i \cap B_1^C) \PP(A) \\
		& = \PP(\bigcap_{i \in I} B_i) \PP(A)
	\end{align*}
	ומצאנו כי ניתן להוסיף איבר, בשל כך נוכל לבצע את התהליך איטרטיבית ולקבל את המבוקש.
\end{proof}
\begin{definition}[אי־תלות קבוצת מאורעות]
	קבוצת מאורעות $\{A_1, \dots, A_n\}$ נקראת בלתי־תלויה אם לכל $I \subseteq [n]$ מתקיים
	\[
		\PP(\bigcap_{i \in I} A_i) = \prod_{i \in I} \PP(A_i)
	\]
\end{definition}
\begin{conclusion}
	אם $A_1, \dots, A_n$ בלתי־תלויים, אז גם כל תת־קבוצה של מאורעות היא בלתי־תלויה. \\*
	בפרט $A_1, \dots, A_n$ בלתי־תלויים גורר ש־$A_1, \dots, A_n$ בלתי־תלויים בזוגות.
\end{conclusion}
\begin{proposition}
	קבוצת מאורעות $\{A_1, \dots, A_n\}$ בלתי־תלויה אם ורק אם לכל $i \in [n]$ מתקיים ש־$A_i$ בלתי־תלויה ב־$\{A_1, \dots, A_n\} \setminus \{A_i\}$.
\end{proposition}
\begin{proof}
	לכיוון הראשון, נרצה להראות ש־$A_1$ לא תלוי ב־$\{A_2, \dots, A_n\}$, כלומר לכל $I \subseteq \{2, \dots, n\}$ רוצים להראות ש־$\PP(\bigcap_{i \in I} A_i \cap A_1) = \PP(\bigcap_{i \in I} A_i) \PP(A_1)$ על־ידי
	\[
		\PP(\bigcap_{i \in I} A_i \cap A_1)
		= (\prod_{i \in I} \PP(A_i)) \PP(A_1)
		= \PP(\bigcap_{i \in I} A_i) \PP(A_1)
	\]

	נעבור לכיוון השני.
	צריך להראות שלכל $I \subseteq [n]$ מתקיים $\PP(\bigcap_{i \in I} A_i) = \prod_{i \in I} \PP(A_i)$.
	תהי $I \subseteq [n] = \{ i_1, \dots, i_k \}$ כאשר $|I| = k$. \\*
	לפי ההנחה $A_{i_1}$ בלתי־תלוי ב־$\{ A_j \mid j \in [n] \setminus \{ i_1 \}\}$, לכן נקבל באינדוקציה
	\[
		\PP(\bigcap_{l = 1}^k A_{i_l})
		= \PP(A_{i_1} \cap (\bigcap_{l = 2}^k A_{i_l}))
		= \PP(A_{i_1}) \cdot \PP(\bigcap_{l = 2}^k A_{i_l})
		= \PP(A_{i_1}) \PP(A_{i_2}) \PP(\bigcap_{l = 3}^k A_{i_l})
		= \cdots = \PP(A_{i_1}) \cdots \PP(A_{i_k})
	\]
\end{proof}

\section{שיעור 7 --- 19.11.2024}

\subsection{אי־תלות}
נראה הגדרה שקולה לאי־תלות
\begin{definition}[שקולה לאי־תלות]
	$A_1, \dots, A_n$ בלתי־תלויים אם ורק אם
	\[
		\forall I \subseteq [n], \PP((\bigcap_{i \in I} A_i) \cap (\bigcap_{i \in [n] \setminus I} A_i^C))
		= \prod_{i \in I} \PP(A_i) \prod_{i \in [n] \setminus I} \PP(A_i^C)
	\]
\end{definition}
את השקילות של ההגדרות נראה בתרגיל. \\*
מאורעות $A_1, \dots, A_n$ בלתי־תלויים בהינתן $B$ אם הם בלתי־תלויים לפי פונקציית ההסתברות המותנית ב־$B$, $\PP_B$.
\begin{example}
	בוחרים מטבע באקראי משק ומטילים אותו $n$ פעמים. \\*
	$A_i$ יצא עץ בהטלה ה־$i$ בלתי־תלוי בהינתן בחירת המטבע, $B$ המאורע שנבחר מטבע מסוים.
\end{example}
נרצה לנסות לתת הגדרה חדשה עבור מקרים אינסופיים, נראה שיתקיים
\[
	\forall I \subseteq \NN, \PP(\bigcap_{i \in I} A_i = \prod_{i \in I} \PP(A_i))
\]
אבל היא לא מועילה לנו, נגדיר במקום זאת
\begin{definition}[קבוצה בת־מניה בלתי־תלויה]
	$A_1, A_2, \dots$ מאורעות הם בלתי־תלויים אם ורק אם \\*
	לכל קבוצה סופית $I$ מתקיים ${\{A_i\}}_{i \in I}$ קבוצה בלתי־תלויה.
\end{definition}
\begin{remark}[מכפלה אינסופית]
	נגדיר מכפלה אינסופית על־ידי
	\[
		\prod_{i \in \NN} a_i
		= \prod_{i = 1}^\infty a_i
		= \lim_{N \to \infty} \prod_{i = 1}^N a_i
	\]
\end{remark}
\begin{proposition}
	אם $A_1, A_2, \dots$ סדרת מאורעות בלתי־תלויים אז
	\[
		\PP(\bigcap_{i \in \NN} A_i) = \prod_{i \in \NN} \PP(A_i)
	\]
\end{proposition}
\begin{proof}
	נגדיר $B_n = \bigcap_{i = 1}^n A_i$ סדרה יורדת ולכן מרציפות פונקציית ההסתברות נובע
	\[
		\PP(\bigcap_{i \in \NN} A_i)
		= \PP(\bigcap_{n \in \NN} B_n)
		= \lim_{n \to \infty} \PP(B_n)
		= \lim_{N \to \infty} \prod_{i = 1}^N \PP(A_i)
		= \prod_{i = 1}^\infty \PP(A_i)
	\]
\end{proof}
\begin{example}
	אם $A_1, \dots$ בלתי־תלויים ו־$\PP(A_i) = p < 1$ אז $\PP(\bigcap_{i \in \NN} A_i) = 0$. \\*
	לדוגמה בהטלה אינסוף פעמים של מטבע הסיכוי שייצא עץ הוא אפס.
	דוגמה זו קצת בעייתית שכן כלל לא הראינו כי מרחב זה קיים ומוגדר, אבל המשמעות היא שעבור מרחבי מדגם הולכים וגדלים, אז ההסתברות המבוקשת שואפת להיות אפס.
\end{example}

\subsection{משתנים מקריים}
עד כה היינו צריכים לבצע ניתוח מלא של הסיטואציה כדי להגיע למסקנה, גם אם בהרבה מקרים שונים הגענו לבדיוק אותה המסקנה, המטרה של משתנים מקריים הוא לבודד את הרעיון הזה ולתקוף אותו.
\begin{definition}[משתנה מקרי]
	יהי $(\Omega, \mathcal{F}, \PP)$ מרחב הסתברות, פונצקיה מ־$\Omega$ ל־$\RR$ נקראת \textbf{משתנה מקרי}.
\end{definition}
\begin{notation}
	על־אף שזו פונקציה, נהוג לסמן משתנים מקריים בסימונים שאנו רגילים שמשמשים למשתנים, לדוגמה $X, Y, Z$.
\end{notation}
\begin{remark}
	השם קצת מטעה, אלו הם לא משתנים, ושווה לחשוב עליהם בתור מצבים מקריים יותר.
\end{remark}
\begin{example}
	נניח $\Omega = \{H, T\}$ הטלת מטבע, ונגדיר את הפונקציה $f : \Omega \to \RR$ על־ידי $f(H) = 2, f(T) = -3$,
	זאת במטרה לייצג שאם יוצא עץ נפסיד שלושה מטבעות ואם מתקבל פלי אז נקבל שני מטבעות.
\end{example}
\begin{example}
	נרצה להטיל שתי קוביות ונרצה לדבר על תוצאת אחת ההטלות, נתחיל ונגדיר $\Omega = {[6]}^2$. \\*
	נגדיר $X_1 : \Omega \to \RR$ על־ידי $X_1(a, b) = a$, ובאופן דומה נגדיר $X_2(a, b) = b$.
	יצרנו פונקציות שמהוות משתנה מקרי עבור ההטלה הראשונה ועבור ההטלה השנייה, נגדיר גם עבור הסכום, $Y(a, b) = a + b$. \\*
	נקבל עתה $Y = X_1 + X_2$, ונבחין בכוח האמיתי של הגדרה זו, יש לנו איזשהו קישור מורכב במרחב ההסתברות ללא עבודה ישירות מול המרחב.
\end{example}
\begin{definition}[משתנה מקרי מושרה ממאורע]
	אם $A$ מאורע אז נגדיר $1_A$ משתנה מקרי על־ידי
	\[
		1_A(\omega) = \begin{cases}
			1, & \omega \in A \\
			0, & \omega \notin A
		\end{cases}
	\]
\end{definition}
\begin{proposition}[תכונות של משתנים מקריים מושרים]
	\begin{enumerate}
		\item $1_{A^C} = 1 - 1_A$
		\item $1_{A \cap B} = 1_A \cdot 1_B$
		\item $1_{A \cup B} = \max\{1_A, 1_B\}$
	\end{enumerate}
\end{proposition}
\begin{example}
	$\Omega = S_n$, $A_i$ המאורע שיש $i$ נקודות שבת. \\*
	נסמן $X_i = 1_{A_i}$ ו־$X = \sum_{i = 1}^n X_i$.
\end{example}
בדוגמות הקודמות ההטלה הראשונה זוגית $\{ (a, b) \in {[6]}^2 \mid a \in \{2, 4, 6\}\}$. נכתוב במקום זאת $X_1 \in \{2, 4, 6\}$.
\begin{definition}[מאורע מושרה ממשתנה מקרי]
	אם $X$ משתנה מקרי ו־$S \in \mathcal{F}_\RR$, המאורע $X \in S$ מוגדר להיות
	\[
		X^{-1}(S) = \{ \omega \in \Omega \mid X(\omega) \in S \}
	\]
	בהתאם נכתוב $\PP(\{x \in S\})$ על־ידי $\PP(X \in S)$, ובאופן דומה נוכל לציין גם את $\PP(X = s), \PP(X \le s)$ ודומים.
\end{definition}
\begin{definition}[פונקציית הסתברות מושרית ממשתנה מקרי]
	$(\Omega, \mathcal{F}, \PP)$ מרחב הסתברות, ויהי $X$ משתנה מקרי. \\*
	נגדיר פונקציה $\PP_X : \mathcal{F}_\RR \to [0, \infty)$ על־ידי
	\[
		\PP_X(S) = \PP(X \in S) = \PP(\{\omega \in \Omega \mid X(\omega) \in S \})
	\]
	$\PP_X$ מכונה ה\textbf{ההתפלגות} של $X$. \\*
	אם $\PP_X$ נתמכת על $S$ (כלומר $\PP_X(S) = 1$) אז אומרים ש־$X$ נתמך על $S$.
\end{definition}
\begin{proposition}
	$\PP_X$ היא פונקציית הסתברות על $(\RR, \mathcal{F}_\RR)$.
\end{proposition}
\begin{proof}
	\[
		\forall S, \PP_X(S) = \PP(X \in S) \ge 0
	\]
	וכן
	\[
		\PP_X(\RR) = \PP(X \in \RR) = \PP(\Omega) = 1
	\]
	ולבסוף סיגמא־אדיטיביות:
	\begin{align*}
		\forall S_1, S_2, \dots, \PP_X(\biguplus_{n \in \NN} S_n)
		& = \PP(X \in \biguplus_{n \in \NN} S_n) \\
		& = \PP(\{\omega \in \Omega \mid X(\omega) \in \biguplus_{n \in \NN} S_n \}) \\
		& = \PP(\biguplus_{n \in \NN} \{ X \in S_n \}) \\
		& = \sum_{n \in \NN} \PP(X \in S_n) \\
		& = \sum_{n \in \NN} \PP_X(S_n)
	\end{align*}
\end{proof}

\section{תרגול 4 --- 21.11.2024}

\subsection{אי־תלות}
נניח מרחב הסתברות $(\Omega, \mathcal{F}, \PP)$.
\begin{exercise}
	בכד שלושה מטבעות, שניים הוגנים ואחד שמוטבע עץ על שני צדדיו. \\*
	שולפים מטבע באקראי ואז מטילים אותו פעמיים. \\*
	האם תוצאת ההטלה הראשונה תלויה בתוצאת ההטלה השנייה?
\end{exercise}
\begin{solution}
	נסמן ב־$A_i$ את המאורע שבהטלה ה־$i$ יצא עץ. \\*
	אנו שואלים אם $A_1, A_2$ הם תלויים, נסמן גם $F$ המאורע ששלפנו מטבע הוגן.
	\[
		\PP(A_1)
		= \PP(A_1 \mid F) \PP(F) + \PP(A_1 \mid F^C) \PP(F^C)
		= \frac{1}{2} \cdot \frac{2}{3} + 1 \cdot \frac{1}{3} = \frac{2}{3}
	\]
	אנו רוצים לבדוק את התלות ולכן נחשב
	\[
		\PP(A_1 \cap A_2)
		= \PP(A_1 \cap A_2 \mid F) \PP(F) + \PP(A_1 \cap A_2 \mid F^C) \PP(F^C)
		= \frac{1}{4} \cdot \frac{2}{3} + 1 \cdot \frac{1}{3} = \frac{1}{2} \ne \frac{4}{9} = \PP(A_1) \cdot \PP(A_2)
	\]
	ולכן הם תלויים.
\end{solution}
\begin{exercise}
	נגדיר $\Omega = \NN$ ו־$\PP(\{n\}) = \frac{1}{c \cdot n^2}$, כאשר $c = \sum_{n \in \NN} \frac{1}{n^2} = \frac{\pi^2}{6}$. \\*
	נגדיר $\forall k \in \NN, A_k = k \NN = \{ kn \mid n \in \NN \}$. \\*
	האם ${\{A_k\}}_{k \in \NN}$ היא תלויה?
\end{exercise}
\begin{solution}
	\[
		\PP(A_k) = \sum_{n \in \NN} \PP(\{k_n\})
		= \sum_{n \in \NN} \frac{1}{c k^2 n^2}
		= \frac{1}{c k^2} \sum_{n \in \NN} \frac{1}{n^2}
		= \frac{1}{k^2}
	\]
	ולכן
	\[
		\PP(A_2 \mid A_4) = 1 \ne \frac{1}{4} = \PP(A_2)
	\]
	ולכן המאורעות תלויים ובכלל הקבוצה לא בלתי־תלויה.
\end{solution}
\begin{exercise}
	נגדיר $P$ קבוצת המספרים הראשוניים, האם ${\{A_p\}}_{p \in P}$ בלתי־תלויה?
\end{exercise}
\begin{solution}
	יהיו $p_1, \dots, p_m \in P$ ראשוניים, אז מהמשפט היסודי של האריתמטיקה (או פירוק לגורמים ראשוניים)
	\[
		A_{p_1} \cap \cdots \cap A_{p_m} = A_{p_1 \cdots p_m}
	\]
	ולכן
	\[
		\PP(A_{p_1} \cap \cdots \cap A_{p_m}) = \PP(A_{p_1 \cdots p_m}) = \frac{1}{{(p_1 \cdots p_m)}^2}
		= \frac{1}{p_1^2} \cdots \frac{1}{p_m^2} = \PP(A_{p_1}) \cdots \PP(A_{p_m})
	\]
	נגדיר גם $B = \bigcap_{p \in P} A_p^C = \{ 1 \}$, ונחשב
	\[
		\frac{6}{\pi^2} = \frac{1}{c} = \PP(B) = \prod_{p \in P} (1 - \frac{1}{p^2})
	\]
\end{solution}
\begin{conclusion}
	נוכל להסיק מסקנה משמעותית נוספת, לכל $s > 1$ מתקיים
	\[
		\sum_{n = 1}^\infty \frac{1}{n^2} = \prod_{p \in P} {(1 - \frac{1}{ps})}^{-1} = \zeta(s)
	\]
	הערך ה־$s$ של פונקציית זטא של רימן, וזו זהות אוילר לפונקציית זטא.
\end{conclusion}
\begin{conclusion}
	מסקנה נוספת היא שבשל אי־רציונליות $\pi$ נוכל להסיק כי הטור הוא לא טור סופי, לכן יש אינסוף ראשוניים.
\end{conclusion}

\subsection{משתנים מקריים}
אנו רוצים להסתכל על משתנה מקרי כדרך להסתכל מחדש על מרחב ההסתברות ובפרט פונקציית ההסתברות באופן נוסף, זה בתורו יאפשר לנו לפתור בעיות בדרך חדשה ואולי אף פשוטה יותר, כפי שנראה בהמשך.
\begin{example}
	נגדיר $X$ להיות משתנה מקרי שמתאר סכום הטלת שתי קוביות הוגנות, דהינו נוכל להגדיר $\PP = {[6]}^2$ ו־$\PP$ אחידה. \\*
	בהתאם נגדיר $X : \Omega \to \RR$ על־ידי $(a, b) \mapsto a + b$. \\*
	לכן
	\[
		\rng(X) = \{2, \dots, 12 \}
	\]
	נעבור לחישוב הסתברויות
	\begin{align*}
		& \PP(X = 2) = \frac{1}{36}, \\
		& \PP(X = 3) = \frac{2}{36}, \\
		& \PP(X = 4) = \frac{3}{36}, \\
		& \PP(X = 5) = \frac{4}{36}, \\
		& \PP(X = 6) = \frac{5}{36}, \\
		& \PP(X = 7) = \frac{6}{36}, \\
		& \PP(X = 8) = \frac{5}{36}
	\end{align*}
	וכן הלאה, בהתאם נוכל להסיק
	\[
		\forall E \subseteq \RR,
		\PP(X \in E)
		= \PP_X(E \cap \rng(X))
		= \sum_{i \in E \cap \rng(X)} \PP(X = i)
	\]
	נסמן $X_i$ תוצאת ההטלה ה־$i$, ולכן $X = X_1 + X_2$, נחשב את $X$ ביחס ל־$X_i$.
	\begin{align*}
		\forall n \in \{2, \dots, 12\},
		\PP(X = n) 
		& = \sum_{i = 1}^{6} \PP(X_1 = i) \PP(X_2 = n - i) \\
		& = \sum_{i = 1}^{6} \frac{1}{6} \min\{6 - i, 0\} \\
		& = \frac{1}{36} |\{\{1, \dots, 6\} \cap \{n - 1, \dots, n - 6 \}\}|
	\end{align*}
	אם נגדיר $Y = X (\mod 6)$ אז $\rng(Y) = \{0, \dots, 5\}$ ונחשב
	\begin{align*}
		\forall n \in \{0, \dots, 5\},
		\PP(Y = n)
		& = \PP(X = n \lor X = n + 6 \lor X = n + 12) \\
		& = \frac{1}{36} \cdot |\{1, \dots, 6\} \cap \{n + 12, \dots, n - 6\}| \\
		& = \frac{6}{36} = \frac{1}{6}
	\end{align*}
\end{example}

\section{שיעור 8 --- 21.11.2024}

\subsection{משתנים מקריים --- המשך}
\begin{definition}[משתנה מקרי בדיד]\label{def_discrete_random_variable}
	$X$ משתנה מקרי נקרא \textbf{בדיד} אם $\PP_X$ הוא פונקציית הסתברות בדידה. \\*
	במקרה זה יש ל־$X$ התפלגות נקודתית $p_X : \RR \to [0, \infty)$.
\end{definition}
\begin{remark}
	נבחין כי גם אם מרחב ההסתברות הוא לא בדיד, נוכל להגדיר משתנה מקרי בדיד עליו.
\end{remark}
\begin{example}
	נגדיר $A \in \mathcal{F}$ ו־$X = 1^A$ ונניח $\PP(A) = p$. \\*
	אם $S \subseteq \mathcal{F}_\RR$ אז אם $\{0, 1 \} \in S$ אז $\Omega = X^{-1}(S)$ ואז $\PP_X(S) = \PP(\Omega) = 1$. \\*
	אם $1 \in S$ אבל $0 \notin S$ אז $A = X^{-1}(S)$ ואז $\PP_X(S) = \PP(A) = p$. \\*
	לבסוף אם $0 \in S$ ו־$1 \notin S$ אז $A^C = X^{-1}(S)$ אז $\emptyset = X^{-1}(S)$ ואז $\PP_X(S) = \PP(\emptyset) = 0$.

	אם נגדיר $p_X : \RR \to [0, \infty)$ על־ידי
	\[
		p_X(s) = \begin{cases}
			p & s = 1 \\
			1 - p & s = 0 \\
			0 & \text{else}
		\end{cases}
	\]
	אז מתקיים
	\[
		\PP_X(S) = \sum_{s \in S} p_X(s)
	\]
\end{example}
\begin{definition}[התפלגות ברנולי]
	משתנה מקרי $X$ מתפלג ברנולי עם פרמטר $p$ אם יש לו פונקציית התפלגות נקודתית
	\[
		p_X(s) = \begin{cases}
			p & s = 1 \\
			1 - p & s = 0 \\
			0 & \text{else}
		\end{cases}
	\]
	במקרה זה נסמן $X \sim \text{Ber}(p)$, סימון לא מאוד מועיל או מתכתב עם השימוש הסטנדרטי, אבל אלה הם החיים.
\end{definition}
נשאל את עצמנו את השאלה האם כל משתנה מקרי מתפלג ברנולי הוא מציין של מאורע.
אילו נגדיר $A = X^{-1}(1)$ אז מתקבל $X = 1_A$, אנו אומרים ש־$X$ שווה למציין של $1_A$ כמעט תמיד, נראה זאת בהמשך הפרק. \\*
נמשיך לעוד מקרים.
\begin{definition}[משתנה מקרי קבוע]
	משתנה מקרי $X$ הוא קבוע אם
	\[
		p_X(s) = \begin{cases}
			1 & s = c \\
			0 & \text{else}
		\end{cases}
	\]
	עבור $c$ קבוע כלשהו.
\end{definition}
\begin{definition}[משתנה מקרי אחיד]
	משתנה מקרי $X$ נקרא אחיד על $S$ תת־קבוצה סופית של $\RR$ אם
	\[
		p_X(s) = \begin{cases}
			\frac{1}{|S|} & s \in S \\
			0 & \text{else}
		\end{cases}
	\]
	במקרה זה נסמן $X \sim U(S)$.
\end{definition}
\begin{definition}[התפלגות גאומטרית]\label{geometric_distribution}
	$X$ מתפלג גאומטרית עם פרמטר $p$ אם
	\[
		p_X(s) = \begin{cases}
			{(1 - p)}^{s - 1} p & s \in \{1, 2, \dots \} \\
			0 & \text{else}
		\end{cases}
	\]
	ונסמן $X \sim \text{Geo}(p)$. \\*
	לפעמים הגדרה זו תסומן אחרת על־ידי מדידת המקרים שבהם יצאה ההסתברות למאורע הראשון בלבד. \\*
	התפלגות זו מתארת את המקרה שניסינו לקבל תוצאה בהסתברות בין שני מקרים וקיבלנו אותה בפעם ה־$s$.
\end{definition}
\begin{definition}[התפלגות בינומית]
	$X$ מתפלג בינומית עם פרמטרים $n$ ו־$p$ אם
	\[
		p_X(s) = \begin{cases}
			\binom{n}{s} p^s {(1 - p)}^{n - s} & s \in \{1, 2, \dots\} \\
			0 & \text{else}
		\end{cases}
	\]
	ונסמן $X \sim \text{Bin}(n, p)$.
\end{definition}
מאפשר לנו לחשב את מספר המטבעות המוטים שיצאו על צד מסוים.
ולבסוף
\begin{definition}[התפלגות פואסונית]
	$X$ מתפלג פואסונית עם פרמטר $\lambda$ אם
	\[
		p_X(s) = \begin{cases}
			e^{-\lambda} \frac{\lambda^s}{s!} & s \in \{0, 1, 2, \dots\} \\
			0 & \text{else}
		\end{cases}
	\]
	ונסמן $X \sim \text{Po}(\lambda)$.
\end{definition}
בפעם הראשונה ההתפלגות הזו הופיעה בהקשר של מספר החיילים שנהרגו מבעיטה מהסוס שלהם, התפלגות שהייתה מהותית עד מלחמת העולם הראשונה.

\subsection{קשרים בין משתנים־מקריים}
\begin{example}
	$\Omega = {[6]}^2$ מרחב אחיד להטלת שתי קוביות, ונגדיר שוב $Y = X_1 + X_2$ סכום הטלות שתי הקוביות, דהינו
	\[
		X_1(a, b) = a,
		X_2(a, b) = b,
		Y(a, b) = a + b
	\]
	בתרגול מצאנו את הערכים של $p_Y$ לכל ערך אפשרי. \\*
	נגדיר גם $Z = Y \mod 6$ (ומנוחות נגדיר $Z \in [6]$), ונשאל מה ההתפלגות של $Z$.
	\[
		p_Z(1) = \PP(Z = 1) = \PP(Y = 7) = \frac{1}{6}
	\]
	באופן דומה
	\[
		p_Z(2) = \PP(Z = 2) = \PP(Y = 2) + \PP(Y = 8) = \frac{1}{36} + \frac{5}{36} = \frac{1}{6}
	\]
	באופן כללי מתקיים מחישוב כזה ש־$p_Z(n) = \frac{1}{6}$ לכל $n \in [6]$, נסיק כי $Z \sim U([6])$.
\end{example}
\begin{definition}[הסתברות כמעט תמיד]
	אם $A$ מאורע עם הסתברות $1$ אז אומרים שהוא מתרחש כמעט תמיד.
\end{definition}
\begin{definition}[משתנים שווים שמעט תמיד]
	אם $X$ ו־$Y$ המקיימים ש־$X = Y$ כמעט תמיד אז נסמן $X \overset{a.s.}{=} Y$. \\*
	זה כמובן שקול להגדרה כי $\PP(\{ \omega \in \Omega \mid X(\omega) = Y(\omega) \}) = 1$ וזה נכון אם ורק אם $\PP(\{\omega \in \Omega \mid X(\omega) \ne Y(\omega) \}) = 0$.
\end{definition}
\begin{exercise}
	הוכיחו כי אם $X \overset{a.s.}{=} Y$ וגם $Y \overset{a.s.}{=} Z$ אז גם $X \overset{a.s.}{=} Z$, דהינו זהו יחס טרנזיטיבי.
\end{exercise}
\begin{proof}
	נשים לב לעובדה הבאה, אם $X(\omega) = Y(\omega)$ ו־$Y(\omega) = Z(\omega)$ עבור $\omega \in \Omega$ כלשהו, אז $X(\omega) = Z(\omega)$,
	כלומר
	\[
		\{ \omega \in \Omega \mid X(\omega) = Y(\omega) \} \cap \{ \omega \in \Omega \mid Y(\omega) = Z(\omega) \} \subseteq \{ \omega \in \Omega \mid X(\omega) = Z(\omega) \}
	\]
	ובהתאם גם
	\[
		\{ \omega \in \Omega \mid X(\omega) \ne Y(\omega) \} \cup \{ \omega \in \Omega \mid Y(\omega) \ne Z(\omega) \} \supseteq \{ \omega \in \Omega \mid X(\omega) \ne Z(\omega) \}
	\]
	אז מחסם האיחוד נקבל
	\[
		0 \le \{ \omega \in \Omega \mid X(\omega) \ne Z(\omega) \} \le 0 + 0
	\]
\end{proof}
\begin{proposition}
	$\overset{a.s.}{=}$ הוא יחס שקילות על מרחב כל המשתנים־המקריים על $\Omega$.
\end{proposition}
\begin{proof}
	ראינו עתה טרנזיטיביות, וסימטריה ורפלקסיביות נובעות ישירות מההגדרה.
\end{proof}
\begin{exercise}
	האם בדוגמה קודם מתקיים $X_1 \overset{a.s.}{=} X_2$?
\end{exercise}
\begin{solution}
	מחישוב מתקיים $\PP(X_1 = X_2) = \frac{1}{6}$ ולכן התשובה היא שלא. \\*
	נבחין כי גם $\PP(X_1 \ne Z) \ge \PP(X_1 = 2, Z = 3) = \PP(\{(2, 1)\}) = \frac{1}{36}$.
\end{solution}
באופן יותר כללי גם אם יש מאורעות שיש להם אותה ההסתברות, אין הכרח שיהיה קשר לשוויון שלהם כמעט תמיד.
\begin{definition}[משתנים  מקריים שווי התפלגות]
	אם למשתנים מקריים $X, Y$ יש אותה פונקציית התפלגות, דהינו $\PP_Y = \PP_X$, \\*
	דהינו מתקיים $\forall S \in \mathcal{F}_\RR, \PP_X(S) = \PP_Y(S) \iff \PP(X \in S) = \PP(Y \in S) \iff \PP(X^{-1}(S)) = \PP(Y^{-1}(S))$, \\*
	אז נאמר שהם שווי התפלגות ונסמן $X \overset{d}{=} Y$.
\end{definition}
ראינו שיש משתנים מקריים $X$ ו־$Y$ כך ש־$X \overset{a.s.}{\ne} Y$ אבל $X \overset{d}{=} Y$,
האם $X \overset{a.s.}{=} Y$ גורר $X \overset{d}{=} Y$?
התשובה היא שכן!
\begin{proposition}
	אם $X \overset{a.s.}{=} Y$ אז גם $X \overset{d}{=}$.
\end{proposition}
\begin{proof}
	נניח ש־$X \overset{a.s.}{=} Y$ ונרצה להוכיח ש־$\forall S \in \mathcal{F}_\RR, \PP(X \in S) = \PP(Y \in S)$. \\*
	לכל $S \in \mathcal{F}_\RR$ מתקיים
	\[
		0 \ne \PP(X \ne Y) \ge \PP(X \in S, Y \notin S) = 0
	\]
	ובהתאם
	\[
		\PP(X \in S) = \PP(X \in S, Y \in S) + \overbrace{\PP(X \in S, Y \notin S)}^{= 0} = \PP(X \in S, Y \in S)
	\]
	כמו־כן גם $\PP(Y \in S) = \PP(X \in S, Y \in S)$.
\end{proof}

\section{שיעור 9 --- 25.11.2024}

\subsection{וקטורים מקריים}
ניזכר בהגדרה\ \ref{def_discrete_random_variable}:
\begin{definition*}[משתנה מקרי בדיד]
	משתנה מקרי נקרא בדיד אם $\PP_X$ פונקציית הסתברות בדידה, כלומר
	\[
		\forall S \in \mathcal{F}_X, \PP_X(S) = \sum_{s \in S} p_X(s)
	\]
	כאשר $p_X(s) = \PP(X = s) = \PP(X^{-1}(s)) = \PP(\{\omega \in \Omega \mid X(\omega) = s \})$.
\end{definition*}
גם דיברנו על סוגים שונים של התפלגות, לדוגמה
\[
	\forall i \in [6], p_X(i) = \frac{1}{6} \iff X \sim U([6])
\]
או באופן דומה
\[
	\forall k \in \{0, \dots, n\}, p_X(k) = \binom{n}{k} p^k {(1 - p)}^{n - k}
\]
$A$ מתרחש כמעט תמיד אם $\PP(A) = 1$, לכן אם $\PP(X = Y) = 1$ אז נאמר ש־$X = Y$ כמעט תמיד, או נסמן $X \overset{a.s.}{=} Y$. \\*
באופן דומה אם $\PP_X = \PP_Y$ אז נסמן $X \overset{d}{=} Y$ או נאמר ש־$X$ ו־$Y$ שווי התפלגות, וראינו קשר בין שתי ההגדרות.
\begin{example}
	נגדיר הטלת מטבע, $\Omega = \{H, T\}$ ו־$X = 1_{\{H\}}, Y = 1_{\{T\}}$, אז $X \overset{d}{=} Y$ שכן
	\[
		p_X(s) = p_Y(s) = \begin{cases}
			\frac{1}{2} & s = 0 \\
			\frac{1}{2} & s = 1 \\
			0 & \text{else}
		\end{cases}
	\]
	אבל גם $\PP(X = Y) = 0$ ולכן $X \overset{a.s.}{\ne} Y$.
\end{example}
\begin{proposition}
	אם $X \overset{d}{=} Y$ ו־$f \in \mathcal{F}_{\RR \to \RR}$ אז $f(X) \overset{d}{=} f(Y)$.
\end{proposition}
\begin{proof}
	נגדיר $W = f(Y), Z = f(X)$,
	צריך להוכיח ש־$\forall S \in \mathcal{F}_\RR, \PP_Z(S) = \PP_W(S)$.
	\begin{align*}
		\PP_Z(S)
		& = \PP(Z \in S) \\
		& = \PP(\{\omega \in \omega \mid Z(\omega) \in S\}) \\
		& = \PP(\{\omega \in \omega \mid f(X(\omega)) \in S\}) \\
		& = \PP(\{\omega \in \omega \mid X(\omega) \in f^{-1}(S)\}) \\
		& = \PP(X \in f^{-1}(S)) \\
		& = \PP_X(f^{-1}(S)) \\
		& = \PP_Y(f^{-1}(S)) \\
		& = \PP(\{\omega \in \omega \mid Y(\omega) \in f^{-1}(S)\}) \\
		& = \PP(\{\omega \in \omega \mid f(Y(\omega)) \in S\}) \\
		& = \PP(W \in S) \\
		& = \PP_W(S)
	\end{align*}
\end{proof}
\begin{example}
	נניח ש־$X \sim Ber(\frac{1}{2})$ וגם $Y \sim Ber(\frac{1}{2})$, ונרצה לחשב את $\PP(X = Y)$. \\*
	אין לנו את היכולת לעשות זאת כי אין מספיק מידע.
\end{example}
\begin{definition}[וקטור מקרי]
	וקטור מקרי הוא משתנה מקרי לתוך $\RR^n$ במקום ל־$\RR$, $X : \Omega \to \RR^n$.
\end{definition}
כלל ההגדרות נשארות זהות פרט להגדרה זו, לדוגמה $\PP_X(S) = \PP(X \in S)$. \\*
המוטיב שלנו הוא היכולת לבנות כמה משתנים מקריים ולעבוד איתם כיציר בודד, לדוגמה $X = (X_1, X_2)$ עבור $X_1, X_2 : \Omega \to \RR$ משתנים מקריים. \\*
\begin{definition}[התפלגות משותפת והתפלגויות שוליות]
	אם $X_1, \dots, X_n$ משתנים מקריים המוגדרים על $\Omega$ יחיד אז $X = (X_1, \dots, X_n)$ הוא וקטור מקרי המוגדר על $\Omega$ וההתפלגות שלו נקראת ההתפלגות המשותפת של $X_1, \dots, X_n$. \\*
	ההתפלגויות של כל אחד מ־$X_1, \dots, X_n$ נקראות ההתפלגויות השוליות.
\end{definition}
השם הזה נובע מהגישה שבה נוכל להבין את ההסתברות של משתנה מקרי בודד מתוך הווקטור על־ידי, אם $X_1, X_2$ מרחבים מקריים אז
\[
	\PP_{X_1}(S) = \PP_{(X_1, X_2)}(S \times \RR) = \PP(\{\omega \in \in \Omega \mid (X_1(\omega), X_2(\omega)) \in S\})
\]
\begin{example}
	אם $\Omega = {[6]}^2$ ו־$X_1(a, b) = a, X_2(a, b) = b$ אז $X = (X_1, X_2)$ כאשר $X : \Omega \to \RR^2$ פונקציית הזהות.
\end{example}
\begin{example}
	נבחן עבור $E = \{(s, y) \in \RR^2 \mid s \le t\}$ את
	\[
		\PP_{(X, Y)}(E)
		= \PP(X \le Y)
	\]
\end{example}
\begin{definition}[התפלגות משותפת בדידה]
	אם לווקטור המקרי התפלגות בדידה, כלומר $\PP_{(X_1, \dots, X_n)}$ פונקציית הסתברות בדידה, \\*
	אז נאמר שההתפלגות המשותפת של $X_1, \dots, X_n$ בדידה.
\end{definition}
\begin{proposition}
	ההתפלגות המשותפת של $X_1, \dots, X_n$ בדידה אם ורק אם ההתפלגות של כל אחד מ־$X_1, \dots, X_n$ בדידה.
\end{proposition}
\begin{proof}
	נוכיח את הכיוון הראשון. \\*
	נניח $\PP_{X_1, \dots, X_n}$ בדידה, אך זה נכון אם ורק אם היא נתמכת על־ידי קבוצה בת־מניה, נבחר קבוצה $S \in \mathcal{F}_\RR$ כזו. \\*
	נסמן ב־$S_1$ את ההטלה של $S$ על הקורדינטה הראשונה, לכן $\PP_{X_1}(S_1) = \PP_{(X_1, X_2)}(S_1 \times \RR)$ אבל $S \subseteq S_1 \times \RR$. \\*
	לכן $X_1$ נתמך על־ידי קבוצה בת־מניה, $S_1$, ולכן הוא בדיד.

	נעבור לכיוון השני. \\*
	נניח ש־$X_1, X_2$ בדידים, לכן קיימות $S_1, S_2 \in \mathcal{F}_\RR$ בנות־מניה, \\*
	כך ש־$\PP(X_1 \in S_1) = \PP(X_2 \in S_2) = 1$. \\*
	לכן $\PP((X_1, X_2) \in S_1 \times S_2) = \PP(X_1 \in S_2, X_2 \in S_2) = 1$. \\*
	$S_1, S_2$ בנות־מניה ולכן נובע ש־$S_1 \times S_2$ בת־מניה.

	כמובן לווקטורים בגודל $n > 2$ ההוכחה דומה.
\end{proof}

\section{תרגול 5 --- 28.11.2024}

\subsection{משתנים מקריים}
בהרצאה זו נניח שכל המשתנים המקריים הם בדידים.
\begin{definition}[התניה במשתנים מקריים בדידים]
	אם $X : \Omega \to \RR^d$ ו־$A \subseteq \Omega$ כך ש־$\PP(A) > 0$ אז
	\[
		\forall S \subseteq \RR^d, \PP_{X \mid A}(S) = \PP(X \in S \mid A) = \PP_A(X \in S)
	\]
\end{definition}
\begin{definition}[אי־תלות במשתנים מקריים בדידים]
	אם $X, Y : \Omega \to \RR^d$ בלתי־תלויים אם לכל $S, T \subseteq \RR^d$ מתקיים
	\[
		\PP(X \in S, Y \in T) = \PP(X \in S) \cdot \PP(Y \in T)
	\]
\end{definition}
\begin{exercise}
	יהיו $X_1, X_2 Geo(p)$ בלתי־תלויים ונגדיר גם $Z = X_1 + X_2$.
	\begin{enumerate}
		\item חשבו את ההתפלגות המשותפת של $X_1$ ו־$Z$.
		\item הראו ש־$X_1 \mid \{ Z = 1 \}$ מתפלג אחיד על $\{1, \dots, n - 1\}$.
	\end{enumerate}
\end{exercise}
\begin{solution}
	תחילה ניזכר שאם $W \sim Geo(p)$ אז $Supp(W) = \NN$ ו־$\PP(W = k) = {(1 - p)}^{k - 1} p$, שכן זוהי ההסתברות שלא הצלחנו $k - 1$ פעמים ובניסיון ה־$k$ הצלחנו, עבור איזושהי פעולה.
	\begin{enumerate}
		\item אנו מגדירים $X = (X_1, Z)$ וקטור מקרי ואנו רוצים לחשב את ההתפלגות שלו, נחשב את התומך
			\[
				Supp(X_1, Z) \subseteq \NN^2
			\]
			ישירות מההגדרה של הווקטור, אבל אנו יודעים כי תמיד $X_1 < Z$, וכן גם אם $m < n$
			\begin{align*}
				P_{(X_1, Z)}(m, n)
				& = \PP(X_1 = m, Z = n) \\
				& = \PP(X_1 = m, X_2 = n - m) \\
				& = \PP(X_1 = m) \cdot \PP(X_2 = m - n) \\
				& = {(1 - p)}^{m - 1} p {(1 - p)}^{n - m - 1} p \\
				& = p^2 {(1 - p)}^{n - 2}
			\end{align*}
			ולכן נסיק
			\[
				P_{(X_1, Z)}(n, n) = \begin{cases}
					0 & m \ge n \\
					p^2 {(1 - p)}^{n - 2} & m < n
				\end{cases}
			\]
		\item נבחן את $X_1 \mid \{ Z = n\}$ ונבין מה התומך.
			\[
				Supp(X_1 \mid \{Z = 1\})
				= \{1, \dots, n - 1\}
			\]
			שכן $Z$ מייצג סכום ולכן מהווה חסם ל־$X_1$ יחד עם $Supp(X_1) = \NN$. נעבור לחישוב ההתפלגות
			\[
				\PP(X = m \mid Z = n)
				= \frac{\PP(X = m, Z = n)}{\PP(Z = n)}
				= \frac{p^2 {(1 - p)}^{n - 2}}{\PP(Z = n)}
			\]
			אבל
			\[
				\PP(Z = n)
				= \PP(X_1 + X_2 = n)
				= \sum_{i = 1}^{n - 1}  \PP(X_1 = i, X_2 = n - i)
				= \sum_{i = 1}^{n - 1}  p^2 {(1 - p)}^{n - 2}
				= (n - 1) p^2 {(1 - p)}^{n - 2}
			\]
			זוהי קונבולוציה, לכן נוכל להסיק
			\[
				\PP(X_1 = m \mid Z = n)
				= \frac{p^2 {(1 - p)}^{n - 2}}{(n - 1) p^2 {(1 - p)}^{n - 2}}
				= \frac{1}{n - 1}
			\]
	\end{enumerate}
\end{solution}
\begin{exercise}
	מטילים מטבע הוגן, אם יצא 0 מטילים שוב מטבע הוגן ואם יצא 1 מטילים מטבע מוטה עם הסתברות $p$ ל־1. \\*
	נתחו את התפלגות ההטלה השנייה.
\end{exercise}
\begin{solution}
	נסמן $X$ תוצאת ההטלה הראשונה ו־$Y$ תוצאת ההטלה השנייה. \\*
	מהנתונים נסיק כי $X \sim Ber(\frac{1}{2})$. אנו גם יודעים כי גם $Y$ הוא בהתפלגות ברנולי כלשהי. \\*
	לבסוף אנו גם יודעים שמתקיים $Y \mid \{X = 0\} \sim Ber(\frac{1}{2})$ וגם ש־$Y \mid \{X = 1\} \sim Ber(p)$, לכן
	\[
		\PP(Y = 1)
		= \PP(Y = 1 \mid X = 0) \PP(X = 0) + \PP(Y = 1 \mid X = 1) \PP(X = 1)
		= \frac{1}{2} \cdot \frac{1}{2} + \frac{1}{2} \cdot p
		= \frac{1}{4} + \frac{p}{2}
	\]
\end{solution}
\begin{exercise}
	יהיו $X \sim Ber(p)$ ו־$Y \sim Ber(q)$ בלתי־תלויים. \\*
	חשבו את ההתפלגות של $X \cdot Y$.
\end{exercise}
\begin{solution}
	נתחיל ונראה כי
	\[
		Supp(X Y) = \{0, 1\},
	\]
	וכן גם $XY$ בהתפלגות ברנולי כלשהי, אך
	\[
		\PP(XY = 1)
		= \PP(X = 1, Y = 1)
		= \PP(X = 1) \PP(Y = 1)
		= pq
	\]
	ולכן $XY \sim Ber(pq)$.
\end{solution}

\section{שיעור 10 --- 28.11.2024}
\subsection{התפלגות תחת התניה}
\begin{definition}[התפלגות משתנה מקרי בהינתן מאורע]
	יהי $X$ משתנה מקרי ו־$A$ מאורע כך ש־$\PP(A) > 0$ אז אפשר לדבר על התפלגות $X$ בהינתן $A$.
	זוהי ההתפלגות של $X$ תחת $\PP_A$ במקום $\PP$.
	במקרה זה
	\[
		\PP_{X \mid A}(S) = \PP_A(X \in S) = \PP(\{X \in S\} \mid A)
	\]
\end{definition}
\begin{proposition}
	אם $X \overset{d}{=} Y$ ו־$S \in \mathcal{F}_\RR$ כך ש־$\PP(X \in S) > 0$ וכן $\PP(Y \in S) > 0$, \\*
	אז $X \mid X \in S \overset{d}{=} Y \mid Y \in S$.
\end{proposition}
\begin{example}
	נניח ש־$X, Y \sim U([6])$ ו־$S = [3, \infty)$ אז
	\[
		X \mid X \in S \sim U(\{3, 4, 5, 6\}),
		\qquad
		Y \mid Y \in S \sim U(\{3, 4, 5, 6\})
	\]
\end{example}
\begin{definition}[אי־תלות משתנים מקריים]
	$X$ ו־$Y$ נקראים בלתי־תלויים אם לכל $S, T \in \mathcal{F}_\RR$ המאורעות $X \in S, Y \in T$ בלתי־תלויים. \\*
	הגדרה זו שקולה להגדרה שמתקיים
	\[
		\PP(X \in S, Y \in T) = \PP(X \in S) \cdot \PP(Y \in T)
	\]
\end{definition}
\begin{proposition}
	אם $X$ ו־$Y$ משתנים מקריים בדידים אז $X$ ו־$Y$ בלתי־תלויים אם ורק אם לכל $s, t \in \RR$ מתקיים ש־$X = s$ ו־$Y = t$ בלתי־תלויים. \\*
	טענה זו שקולה לטענה שמתקיים
	\[
		\PP(X = s, Y = t) = \PP(X = s) \cdot \PP(Y = t)
	\]
\end{proposition}
\begin{proof}
	הכיוון הראשון הוא טריוויאלי מבחירת יחידונים ושימשו בהגדרה, לכן נניח את הכיוון השני ונראה כי מתקיים לכל $S, T \in \mathcal{F}_\RR$ מתקיים
	\[
		\PP(X \in S, Y \in T) = \PP(X \in S) \PP(Y \in T)
	\]
	נבחין כי
	\begin{align*}
		\PP(X \in S, Y \in T)
		& = \PP(X \in S \cap Supp(X), Y \in T \cap Supp(Y)) \\
		& = \sum_{\substack{s \in S \cap Supp(X) \\ t \in T \cap Supp(Y)}} \PP(X = s, Y = t) \\
		& = \sum_{\substack{s \in S \cap Supp(X) \\ t \in T \cap Supp(Y)}} \PP(X = s) \PP(Y = t) \\
		& = \sum_{s \in S \cap Supp(X)} \left( \sum_{t \in T \cap Supp(Y)} \PP(X = s) \PP(Y = t) \right) \\
		& = \left( \sum_{s \in S \cap Supp(X)} \PP(X = s) \right) \left( \sum_{t \in T \cap Supp(Y)} \PP(Y = t) \right) \\
		& = \PP(X \in S) \PP(Y \in T)
	\end{align*}
\end{proof}
\begin{proposition}
	התפלגות $X$ ו־$X + Y$ ו־$Y$ בלתי־תלויים קובע ביחידות את ההתפלגות המשותפת.
\end{proposition}
\begin{proof}[הוכחה עבור בדידים]
	$p_X$ ו־$p_Y$ בלתי־תלויים קובע את $p_{(X, Y)}(s, t) = p_X(s) p_Y(t)$.
\end{proof}
\begin{proposition}
	$X, Y, Z$ משתנים מקריים בדידים ונניח שלכל $s \in Supp(X)$ מתקיים $Y \mid X = s \overset{d}{=} Z$,
	אז $Y \overset{d}{=} Z$ ו־$X, Y$ בלתי־תלויים.
\end{proposition}
\begin{proof}
	מנוסחת ההסתברות השלמה נובע
	\begin{align*}
		\PP(Y = t)
		& = \sum_{s \in Supp(X)} \PP(X = s) \PP(Y = t \mid X = s) \\
		& = \sum_{s \in Supp(X)} \PP(X = s) \PP(Z = t) \\
		& = \PP(Z = t)
	\end{align*}
	עבור החלק השני נבחין כי
	\[
		\PP(X = s, Y = t)
		= \PP(X = s) \PP(Y = t \mid X = s)
		= \PP(X = s) \PP(Z = t)
		= \PP(X = s) \PP(Y = t)
	\]
\end{proof}
\begin{proposition}
	אם $X, Y$ משתנים מקריים בלתי־תלויים ו־$f, g \in \mathcal{F}_{\RR \to \RR}$ אז $f(X), g(Y)$ בלתי־תלויים.
\end{proposition}
\begin{proof}
	צריך להראות שלכל $S, T \in \mathcal{F}_{\RR}$ מתקיים
	\[
		\PP(f(X) \in S, g(Y) \in T) = \PP(f(X) \in S) \PP(g(Y) \in T)
	\]
	אבל ראינו כבר כי
	\[
		\PP(f(X) \in S, g(Y) \in T) = \PP(X \in f^{-1}(S), Y \in g^{-1}(T))
	\]
	אבל גם
	\[
		\PP(X \in f^{-1}(S), Y \in g^{-1}(T)) = \PP(f(X) \in S) \PP(g(Y) \in T)
	\]
\end{proof}
\begin{example}
	$X$ ו־$Y$ בלתי־תלויים אז $X^2, \frac{1}{Y}$ בלתי־תלויים, זאת שכן $\PP(X = 1, Y = 1) = \frac{1}{2} \ne \frac{1}{2} \cdot \frac{1}{2}$. \\*
	בכיוון ההפוך אם $X = Y \sim Ber(\frac{1}{2})$ לא בלתי־תלויים אבל אם $f(x) = g(y) = 6$ גוררים ש־$f(X)$ ו־$g(Y)$ הם כמעט תמיד 6 ולכן בלתי־תלויים.
\end{example}
\begin{definition}[קבוצת משתנים מקריים בלתי־תלויה]
	יהיו $X_1, \dots, X_n$ משתנים מקריים, אז הם יקראו בלתי־תלויים אם לכל $S_1, \dots, S_n \in \mathcal{F}_\RR$ המאורעות ${\{ X_i \in S_i \}}_{i \in [n]}$ הם בלתי־תלויים.
\end{definition}
\begin{example}
	אם $X, Y, Z$ הם בלתי־תלויים, האם גם $X + Y$ ו־$Z$ בלתי־תלויים?
	אנו צריכים להראות ש־$\PP(X + Y = s, Z = t) = \PP(X + Y = s) \PP(Z = t)$ עבור כל $s \in \{0, 1, 2\}, t \in \{0, 1\}$. \\*
	נבחר לדוגמה את $\PP(X + Y = 1, Z = 1) = \PP(X = 0, Y = 1, Z = 1) + \PP(X = 1, Y = 0, Z = 1) = \frac{1}{8} + \frac{1}{8}$ ונוכל להמשיך כך ולראות שהטענה אכן מתקיימת.
\end{example}
\begin{exercise}
	מאורעות $A_1, \dots, A_n$ הם בלתי־תלויים אם ורק אם $1_{A_1}, \dots, 1_{A_n}$ הם בלתי־תלויים.
\end{exercise}
\begin{proposition}
	$X_1, \dots, X_n$ משתנים מקריים בלתי־תלויים ונניח שיש אינדקסים $1 = i_0 < i_1 < \cdots < i_k = n$. \\*
	נגדיר $Y_0 = (X_{i_0}, \dots, X_{i - 1}), \dots. Y_k = (X_{i_{k - 1}}, \dots, X_{i_k})$.
\end{proposition}

\section{שיעור 11 --- 3.12.2024}
\subsection{אי־תלות משתנים מקריים}
נמשיך עם מהלך ההרצאה הקודמת.
\begin{proposition}
	יהיו $X_1, \dots, X_n$ משתנים מקריים (יכולים להיות גם וקטורים מקריים ללא השפעה על ההוכחה) בלתי־תלויים,
	ויהיו $1 = b_0 < b_1 < \cdots < b_k = n$ ונגדיר $Y_1 = (X_{b_0 + 1}, \dots, X_{b_1}), \dots, Y_k = (X_{b_{k - 1} + 1}, \dots, X_{b_k})$. \\*
	אז $Y_1, \dots, Y_k$ בלתי־תלויים. \\*
	כדוגמה, $X_1, \dots, X_7 \rightarrow \overbrace{(X_1, X_2, X_3)}^{Y_1}, \overbrace{(X_4, X_5)}^{Y_2}, \overbrace{(X_6, X_7)}^{Y_3}$.
\end{proposition}
\begin{proof}[הוכחה במקרה הבדיד]
	$Y_i$ הוא וקטור מקרי ממימד $b_i - b_{i - 1}$, צריך להוכיח שלכל $s_1, \dots, s_k$ כך ש$s_1 \in \RR^{b_i - b_{i - 1}}$ מתקיים
	\[
		\PP(\forall i \in k, Y_i = s_i) = \prod_{i = 1}^k \PP(Y_i = s_i)
	\]
	נניח ש־$s_i = (a_{i 1}, \dots, a_{i d_i})$ ולכן נסיק מחוסר התלות של $X_i$
	\[
		\prod_{i = 1}^k \PP(Y_i = s_i)
		= \prod_{i = 1}^k \PP(\forall 1 \le j \le d_i, X_{b_{i - 1} + j} = a_{i j})
		= \prod_{i = 1}^k \prod_{j = 1}^{d_i} \PP(X_{b_{i - 1} + j} = a_{i j})
	\]
	אבל
	\[
		PP(\forall i \in k, Y_i = s_i)
		= \PP(\forall j = X_j = c_j)
		= \prod_{j = 1}^h \PP(X_j = c_j)
		= \prod_{i = 1}^k \prod_{j = 1}^{d_i} \PP(X_{b_{i - 1} + j} = a_{i j})
	\]
	עבור
	\[
		c = (\overbrace{a_{11}, \dots, a_{1d_1}}^{s_1}, \dots, \overbrace{a_{k1}, \dots, a_{kd_1}}^{s_k})
	\]
	ומצאנו כי השוויון אכן מתקיים ו־$Y_1, \dots, Y_k$ בלתי־תלויים.
\end{proof}
\begin{conclusion}
	$X_1, \dots, X_n$ בלתי־תלויים ו־$0 = b_0 < b_1 < \cdots < b_k = n - 1$ ו־$d_i = b_i - b_{i - 1}$ כך ש־$Y_i = (X_{b_{i - 1} + 1}, \dots, X_{b_i})$ ו־$f_1, \dots, f_k$ כאשר $f_i : \RR^{d_i} \to \RR$,
	אז ${\{f_i(Y_i)\}}_{i = 1}^k$ בלתי־תלויים.
\end{conclusion}
\begin{example}
	אם $X_1, \dots, X_n$ בלתי־תלויים אז גם $X_1 + X_2, \dots, X_3 + X_4, \dots, X_{n - 1} + X_{n}$ כנביעה מהמסקנה, \\*
	באופן דומה גם $X_1 + X_2 + X_3, \dots$ בלתי־תלויים. \\*
	כרעיון אנו יכולים לחלק משתנים מקריים לווקטורים בלתי־תלויים, ואז להפעיל פונקציה, שלא משנה את חוסר התלות, על כל הקבוצה.
\end{example}
\begin{example}
	נניח ש־$A_1, \dots, A_5$ מאורעות בלתי־תלויים, אז המאורעות $(A_5 \cap A_4) \cup (A_1 \cap A_2) \cup A_3^C, A_4 \setminus A_5$ בלתי־תלויים,
	זאת אנו עושים על־ידי שימוש במשתנים המקריים האופייניים של $A_i$ ושימוש במסקנה.
\end{example}
נבחין כי דרישת סופיות קבוצת המשתנים המקריים היא לא תנאי הכרחי
\begin{definition}[קבוצה בת־מניה של משתנים מקריים בלתי־תלויים]
	$X_1, X_2, \dots$ משתנים מקריים הם בלתי־תלויים אם לכל $n \in \NN$ מתקיים $X_1, \dots, X_n$ בלתי־תלויים.
\end{definition}
\begin{proposition}
	אם ${\{X_n\}}_{n \in \NN}$ בלתי־תלויים ו־$S_n \in \mathcal{F}_\RR$ לכל $n \in \NN$ אז
	\[
		\PP(\forall n \in \NN, X_n \in S_n)
		= \prod_{n \in \NN} \PP(X_n \in S_n)
	\]
\end{proposition}
נשאל את עצמנו אם מצב זה בכלל אפשרי, נראה טענה ללא הוכחה שעונה על שאלה זו.
\begin{proposition}
	קיימת סדרת משתנים מקריים כזאת שכולם $Ber(\frac{1}{2})$.
\end{proposition}
\begin{proposition}
	סדרה כזו בהכרח לא מוגדרת על מרחב בדיד.
\end{proposition}
\begin{proof}
	נניח ש־$X_1, \dots$ סדרה כזו ונניח ש־$(\Omega, \mathcal{F}, \PP)$ בדיד. \\*
	נניח ש־$\omega_0 \in \Omega$ ו־$\PP(\{\omega_0\}) > 0$, נסמן $s_i = X_i(\omega_0)$, אז
	\[
		0 \xleftarrow[n \to 0]{} {\left(\frac{1}{2}\right)}^n = \PP(\forall i \le n, X_i = s_i) \ge \PP(\forall i \in \NN, X_i = s_i) \ge \PP(\{\omega_0\}) > 0
	\]
	וקיבלנו סתירה לקיום $\omega_0$ כזה.
\end{proof}

\subsection{התפלגות גאומטרית}
ניזכר בהגדרה\ \ref{geometric_distribution}, אשר מדברת על ניסוי שאנו עושים שוב ושוב עד שאנו מצליחים.
\begin{proposition}
	אם $X_1, X_2, \dots$ משתנים מקריים בלתי־תלויים המתפלגים $Ber(p)$ עבור $0 < p < 1$, \\*
	ונסמן $Y = \min \{ k \mid X_k = 1 \}$, אז $Y \sim Geo(p)$.
\end{proposition}
נבחין כי $Y$ מייצג בחירת המופע הראשון של $1$ בהתפלגות ברנולי, נזכיר כי היא מייצגת הגרלה יחידה, לדוגמה הטלת מטבע בודד. נעבור להוכחה.
\begin{proof}
	המאורע $Y = l$ הוא המאורע $X_1 = X_2 = \cdots = X_{l - 1} = 0$ ו־$X_l = 1$, אבל שלו הם משתנים בלתי־תלויים, לכן
	\[
		\PP(X_1 = \cdots = X_{l - 1} = 0, X_l = 1)
		= \PP(X_1 = 0) \cdots \PP(X_{l - 1}) \PP(X_l = 1)
		= {(1 - p)}^{l - 1} p
	\]
	זוהי התפלגות גאומטרית.
\end{proof}
\begin{remark}
	הסכום הוא
	\[
		\sum_{l = 1}^{\infty} {(1 - p)}^{l - 1} p = 1
	\]
	ולכן המקרה שבו אין מינימום כפי שהגדרנו לא רלוונטי להגדרה, וניתן להתעלם ממנו.
\end{remark}
מה יקרה אם נגדיר ככה $Y_1 = Y$ ו־$Y_2$ המשתנה המקרי שעבורו קיבלנו 1 בפעם השנייה וכן הלאה, אז $Y_2 - Y_1$ וסדרת החיסורים היא בלתי תלויה־אף היא, תוצאה אינטואיטיבית אך לא מובנת מאליו.

\listoftheorems[title=הגדרות ומשפטים,ignoreall,show={theorem,definition},swapnumber]
\end{document}
